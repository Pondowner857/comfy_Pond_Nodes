import torch
import gc
import comfy.model_management as mm

class WanVideoResourceCleaner:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "any_input": ("*",),  # æ¥å—ä»»ä½•ç±»å‹çš„è¾“å…¥
                "clear_cache": ("BOOLEAN", {"default": True}),
                "force_gc": ("BOOLEAN", {"default": True}),
                "unload_model": ("BOOLEAN", {"default": False}),
            },
        }
    
    RETURN_TYPES = ("*",)  # è¾“å‡ºä»»ä½•ç±»å‹
    RETURN_NAMES = ("any_output",)
    FUNCTION = "clean_resources"
    CATEGORY = "ğŸ³Pond/video"
    DESCRIPTION = "æ¸…ç†èµ„æºå¹¶ä¼ é€’ä»»ä½•ç±»å‹çš„æ•°æ®"
    
    def clean_resources(self, any_input, clear_cache, force_gc, unload_model):
        # è·å–è®¾å¤‡
        device = mm.get_torch_device()
        offload_device = mm.unet_offload_device()
        
        # æ£€æŸ¥è¾“å…¥æ˜¯å¦æ˜¯ WanVideo æ¨¡å‹
        if hasattr(any_input, 'model') and hasattr(any_input.model, 'diffusion_model'):
            # è·å– transformer
            transformer = any_input.model.diffusion_model
            
            # 1. æ¸…ç† block swap çŠ¶æ€
            if hasattr(transformer, 'block_swap'):
                # å°†æ‰€æœ‰å—ç§»å› offload device
                for name, param in transformer.named_parameters():
                    if param.device != offload_device:
                        param.data = param.data.to(offload_device)
            
            # 2. æ¸…ç†ç¼“å­˜çŠ¶æ€
            if hasattr(transformer, 'teacache_state'):
                transformer.teacache_state.clear_all()
            if hasattr(transformer, 'magcache_state'):
                transformer.magcache_state.clear_all()
            
            # 3. æ¸…ç† VAE ç¼“å­˜
            if hasattr(transformer, 'model') and hasattr(transformer.model, 'clear_cache'):
                transformer.model.clear_cache()
        
        # 4. æ¸…ç† CUDA ç¼“å­˜
        if clear_cache:
            mm.soft_empty_cache()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                torch.cuda.synchronize()
        
        # 5. å¼ºåˆ¶åƒåœ¾å›æ”¶
        if force_gc:
            gc.collect()
        
        # 6. å®Œå…¨å¸è½½æ¨¡å‹ï¼ˆå¯é€‰ï¼‰
        if unload_model:
            mm.unload_all_models()
            mm.cleanup_models()
            # å¦‚æœæ˜¯æ¨¡å‹ï¼Œå°† transformer ç§»åˆ° CPU
            if hasattr(any_input, 'model') and hasattr(any_input.model, 'diffusion_model'):
                any_input.model.diffusion_model.to(offload_device)
        
        # æ‰“å°å†…å­˜çŠ¶æ€
        if torch.cuda.is_available():
            allocated = torch.cuda.memory_allocated(device) / 1024**3
            reserved = torch.cuda.memory_reserved(device) / 1024**3
            print(f"GPU å†…å­˜ - å·²åˆ†é…: {allocated:.2f}GB, å·²é¢„ç•™: {reserved:.2f}GB")
        
        # è¿”å›åŸå§‹è¾“å…¥ï¼Œä¿æŒæ•°æ®æµ
        return (any_input,)


class WanVideoResetBlockSwap:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "any_input": ("*",),  # æ¥å—ä»»ä½•ç±»å‹çš„è¾“å…¥
            },
        }
    
    RETURN_TYPES = ("*",)  # è¾“å‡ºä»»ä½•ç±»å‹
    RETURN_NAMES = ("any_output",)
    FUNCTION = "reset_block_swap"
    CATEGORY = "ğŸ³Pond/video"
    DESCRIPTION = "é‡ç½® block swap è®¾ç½®ï¼ˆå¦‚æœè¾“å…¥æ˜¯æ”¯æŒçš„æ¨¡å‹ç±»å‹ï¼‰"
    
    def reset_block_swap(self, any_input):
        # æ£€æŸ¥è¾“å…¥æ˜¯å¦æ˜¯æ”¯æŒçš„æ¨¡å‹ç±»å‹
        if hasattr(any_input, 'clone') and hasattr(any_input, 'model_options'):
            # å…‹éš†æ¨¡å‹ä»¥é¿å…ä¿®æ”¹åŸå§‹æ¨¡å‹
            patcher = any_input.clone()
            
            # æ¸…é™¤ block_swap_args
            if 'transformer_options' in patcher.model_options:
                if 'block_swap_args' in patcher.model_options['transformer_options']:
                    del patcher.model_options['transformer_options']['block_swap_args']
            
            # è·å– transformerï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if hasattr(patcher.model, 'diffusion_model'):
                transformer = patcher.model.diffusion_model
                device = mm.get_torch_device()
                
                # å°†æ‰€æœ‰å‚æ•°ç§»å›ä¸»è®¾å¤‡
                for name, param in transformer.named_parameters():
                    if param.device != device:
                        param.data = param.data.to(device)
                
                # é‡ç½® block swap ç›¸å…³å±æ€§
                if hasattr(transformer, 'use_non_blocking'):
                    transformer.use_non_blocking = False
            
            return (patcher,)
        else:
            # å¦‚æœä¸æ˜¯æ”¯æŒçš„ç±»å‹ï¼Œç›´æ¥è¿”å›åŸå§‹è¾“å…¥
            print("è¾“å…¥ä¸æ˜¯æ”¯æŒçš„æ¨¡å‹ç±»å‹ï¼Œç›´æ¥ä¼ é€’")
            return (any_input,)


NODE_CLASS_MAPPINGS = {
    "WanVideoResourceCleaner": WanVideoResourceCleaner,
    "WanVideoResetBlockSwap": WanVideoResetBlockSwap,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "WanVideoResourceCleaner": "ğŸ³WanVideo Resource Cleaner",
    "WanVideoResetBlockSwap": "ğŸ³WanVideo Reset Block Swap",
}