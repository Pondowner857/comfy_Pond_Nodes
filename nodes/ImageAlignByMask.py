import torch
import torch.nn.functional as F
import numpy as np
from typing import Tuple, Optional, List

class ImageAlignByMask:
    """
    ComfyUIæ’ä»¶ï¼šåŸºäºé®ç½©å¯¹é½çš„å›¾åƒå®šä½
    æ ¹æ®é®ç½©å¯¹é½æ–¹å¼ï¼ŒåŒæ­¥è°ƒæ•´å¯¹åº”çš„å›¾åƒä½ç½®å’Œå°ºå¯¸
    æ‰©å±•åŒºåŸŸå¡«å……ç™½è‰²ã€é»‘è‰²æˆ–é€æ˜
    """
    
    def __init__(self):
        pass
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "åŸºå‡†é®ç½©": ("MASK",),
                "é®ç½©2": ("MASK",),
                "å›¾åƒ2": ("IMAGE",),
                "å¯¹é½æ–¹å¼": (["å±…ä¸­å¯¹é½", "å·¦å¯¹é½", "å³å¯¹é½", "ä¸Šå¯¹é½", "ä¸‹å¯¹é½", 
                           "å·¦ä¸Šå¯¹é½", "å³ä¸Šå¯¹é½", "å·¦ä¸‹å¯¹é½", "å³ä¸‹å¯¹é½"], 
                          {"default": "å±…ä¸­å¯¹é½"}),
            },
            "optional": {
                "Xè½´åç§»": ("INT", {"default": 0, "min": -2048, "max": 2048, "step": 1}),
                "Yè½´åç§»": ("INT", {"default": 0, "min": -2048, "max": 2048, "step": 1}),
                "å¡«å……é¢œè‰²": (["ç™½è‰²", "é»‘è‰²", "é€æ˜"], {"default": "ç™½è‰²"}),
            }
        }
    
    RETURN_TYPES = ("IMAGE", "MASK", "MASK")
    RETURN_NAMES = ("å®šä½åå›¾åƒ", "åŸºå‡†é®ç½©", "å¯¹é½åé®ç½©")
    FUNCTION = "align_image_by_mask"
    CATEGORY = "ğŸ³Pond/image"
    OUTPUT_NODE = False
    
    def get_mask_bounds(self, mask: torch.Tensor) -> Tuple[int, int, int, int]:
        """è·å–é®ç½©ä¸­éé›¶åŒºåŸŸçš„è¾¹ç•Œ"""
        if len(mask.shape) > 2:
            mask = mask.squeeze()
        
        coords = torch.nonzero(mask > 0.01)
        
        if coords.numel() == 0:
            return 0, 0, mask.shape[1], mask.shape[0]
        
        min_y, min_x = coords.min(dim=0)[0]
        max_y, max_x = coords.max(dim=0)[0]
        
        return int(min_x), int(min_y), int(max_x - min_x + 1), int(max_y - min_y + 1)
    
    def calculate_alignment_transform(self, base_bounds: Tuple[int, int, int, int], 
                                    mask2_bounds: Tuple[int, int, int, int], 
                                    base_size: Tuple[int, int],
                                    mask2_size: Tuple[int, int],
                                    alignment: str, 
                                    offset_x: int = 0, 
                                    offset_y: int = 0) -> Tuple[int, int]:
        """è®¡ç®—å¯¹é½æ‰€éœ€çš„å˜æ¢å‚æ•°"""
        base_h, base_w = base_size
        mask2_h, mask2_w = mask2_size
        base_x, base_y, base_w_content, base_h_content = base_bounds
        mask2_x, mask2_y, mask2_w_content, mask2_h_content = mask2_bounds
        
        # æ ¹æ®å¯¹é½æ–¹å¼è®¡ç®—åç§»
        if alignment == "å±…ä¸­å¯¹é½":
            base_center_x = base_x + base_w_content // 2
            base_center_y = base_y + base_h_content // 2
            mask2_center_x = mask2_x + mask2_w_content // 2
            mask2_center_y = mask2_y + mask2_h_content // 2
            
            place_x = base_center_x - mask2_center_x
            place_y = base_center_y - mask2_center_y
            
        elif alignment == "å·¦å¯¹é½":
            place_x = base_x - mask2_x
            base_center_y = base_y + base_h_content // 2
            mask2_center_y = mask2_y + mask2_h_content // 2
            place_y = base_center_y - mask2_center_y
            
        elif alignment == "å³å¯¹é½":
            place_x = (base_x + base_w_content) - (mask2_x + mask2_w_content)
            base_center_y = base_y + base_h_content // 2
            mask2_center_y = mask2_y + mask2_h_content // 2
            place_y = base_center_y - mask2_center_y
            
        elif alignment == "ä¸Šå¯¹é½":
            base_center_x = base_x + base_w_content // 2
            mask2_center_x = mask2_x + mask2_w_content // 2
            place_x = base_center_x - mask2_center_x
            place_y = base_y - mask2_y
            
        elif alignment == "ä¸‹å¯¹é½":
            base_center_x = base_x + base_w_content // 2
            mask2_center_x = mask2_x + mask2_w_content // 2
            place_x = base_center_x - mask2_center_x
            place_y = (base_y + base_h_content) - (mask2_y + mask2_h_content)
            
        elif alignment == "å·¦ä¸Šå¯¹é½":
            place_x = base_x - mask2_x
            place_y = base_y - mask2_y
            
        elif alignment == "å³ä¸Šå¯¹é½":
            place_x = (base_x + base_w_content) - (mask2_x + mask2_w_content)
            place_y = base_y - mask2_y
            
        elif alignment == "å·¦ä¸‹å¯¹é½":
            place_x = base_x - mask2_x
            place_y = (base_y + base_h_content) - (mask2_y + mask2_h_content)
            
        elif alignment == "å³ä¸‹å¯¹é½":
            place_x = (base_x + base_w_content) - (mask2_x + mask2_w_content)
            place_y = (base_y + base_h_content) - (mask2_y + mask2_h_content)
        
        # åº”ç”¨ç”¨æˆ·åç§»
        place_x += offset_x
        place_y += offset_y
        
        return place_x, place_y
    
    def apply_transform_to_image(self, image: torch.Tensor, 
                               place_x: int, place_y: int,
                               target_height: int, target_width: int,
                               fill_color: str) -> torch.Tensor:
        """å°†å˜æ¢åº”ç”¨åˆ°å›¾åƒ"""
        batch, h, w, c = image.shape
        
        # è®¾ç½®å¡«å……å€¼
        if fill_color == "ç™½è‰²":
            fill_value = 1.0
        elif fill_color == "é»‘è‰²":
            fill_value = 0.0
        else:  # é€æ˜
            fill_value = 0.0
            # å¦‚æœæ˜¯é€æ˜ï¼Œç¡®ä¿æœ‰alphaé€šé“
            if c == 3:
                alpha = torch.ones((batch, h, w, 1), dtype=image.dtype, device=image.device)
                image = torch.cat([image, alpha], dim=3)
                c = 4
        
        # åˆ›å»ºè¾“å‡ºå›¾åƒ
        output = torch.full((batch, target_height, target_width, c), 
                          fill_value, dtype=image.dtype, device=image.device)
        
        # å¦‚æœæ˜¯é€æ˜æ¨¡å¼ï¼Œè®¾ç½®alphaé€šé“
        if fill_color == "é€æ˜" and c == 4:
            output[:, :, :, 3] = 0.0  # èƒŒæ™¯é€æ˜
        
        # è®¡ç®—å¤åˆ¶åŒºåŸŸ
        src_x_start = max(0, -place_x)
        src_y_start = max(0, -place_y)
        src_x_end = min(w, target_width - place_x)
        src_y_end = min(h, target_height - place_y)
        
        dst_x_start = max(0, place_x)
        dst_y_start = max(0, place_y)
        dst_x_end = dst_x_start + (src_x_end - src_x_start)
        dst_y_end = dst_y_start + (src_y_end - src_y_start)
        
        # å¤åˆ¶å›¾åƒå†…å®¹
        if src_x_end > src_x_start and src_y_end > src_y_start:
            output[:, dst_y_start:dst_y_end, dst_x_start:dst_x_end] = \
                image[:, src_y_start:src_y_end, src_x_start:src_x_end]
            
            # å¦‚æœæ˜¯é€æ˜æ¨¡å¼ï¼Œè®¾ç½®å¤åˆ¶åŒºåŸŸçš„alphaä¸º1
            if fill_color == "é€æ˜" and c == 4:
                output[:, dst_y_start:dst_y_end, dst_x_start:dst_x_end, 3] = 1.0
        
        return output
    
    def apply_transform_to_mask(self, mask: torch.Tensor,
                              place_x: int, place_y: int,
                              target_height: int, target_width: int) -> torch.Tensor:
        """å°†å˜æ¢åº”ç”¨åˆ°é®ç½©"""
        if len(mask.shape) > 2:
            mask = mask.squeeze()
        
        # åˆ›å»ºè¾“å‡ºé®ç½©
        output = torch.zeros((target_height, target_width), dtype=mask.dtype, device=mask.device)
        
        h, w = mask.shape
        
        # è®¡ç®—å¤åˆ¶åŒºåŸŸ
        src_x_start = max(0, -place_x)
        src_y_start = max(0, -place_y)
        src_x_end = min(w, target_width - place_x)
        src_y_end = min(h, target_height - place_y)
        
        dst_x_start = max(0, place_x)
        dst_y_start = max(0, place_y)
        dst_x_end = dst_x_start + (src_x_end - src_x_start)
        dst_y_end = dst_y_start + (src_y_end - src_y_start)
        
        # å¤åˆ¶é®ç½©å†…å®¹
        if src_x_end > src_x_start and src_y_end > src_y_start:
            output[dst_y_start:dst_y_end, dst_x_start:dst_x_end] = \
                mask[src_y_start:src_y_end, src_x_start:src_x_end]
        
        return output
    
    def align_image_by_mask(self, åŸºå‡†é®ç½©, é®ç½©2, å›¾åƒ2, å¯¹é½æ–¹å¼, 
                           Xè½´åç§»=0, Yè½´åç§»=0, å¡«å……é¢œè‰²="ç™½è‰²"):
        """
        ä¸»å‡½æ•°ï¼šæ ¹æ®é®ç½©å¯¹é½æ–¹å¼è°ƒæ•´å›¾åƒ
        """
        # è·å–åŸºå‡†é®ç½©å°ºå¯¸
        if len(åŸºå‡†é®ç½©.shape) > 2:
            base_h, base_w = åŸºå‡†é®ç½©.shape[1:3]
        else:
            base_h, base_w = åŸºå‡†é®ç½©.shape
        
        # è·å–é®ç½©2å°ºå¯¸
        if len(é®ç½©2.shape) > 2:
            mask2_h, mask2_w = é®ç½©2.shape[1:3]
        else:
            mask2_h, mask2_w = é®ç½©2.shape
        
        # è·å–å†…å®¹è¾¹ç•Œ
        base_bounds = self.get_mask_bounds(åŸºå‡†é®ç½©)
        mask2_bounds = self.get_mask_bounds(é®ç½©2)
        
        print(f"åŸºå‡†é®ç½©å°ºå¯¸: {base_h}x{base_w}")
        print(f"åŸºå‡†é®ç½©å†…å®¹è¾¹ç•Œ: x={base_bounds[0]}, y={base_bounds[1]}, w={base_bounds[2]}, h={base_bounds[3]}")
        print(f"é®ç½©2å°ºå¯¸: {mask2_h}x{mask2_w}")
        print(f"é®ç½©2å†…å®¹è¾¹ç•Œ: x={mask2_bounds[0]}, y={mask2_bounds[1]}, w={mask2_bounds[2]}, h={mask2_bounds[3]}")
        print(f"å¯¹é½æ–¹å¼: {å¯¹é½æ–¹å¼}")
        
        # è®¡ç®—å¯¹é½å˜æ¢
        place_x, place_y = self.calculate_alignment_transform(
            base_bounds, mask2_bounds,
            (base_h, base_w), (mask2_h, mask2_w),
            å¯¹é½æ–¹å¼, Xè½´åç§», Yè½´åç§»
        )
        
        print(f"è®¡ç®—å¾—åˆ°çš„åç§»: x={place_x}, y={place_y}")
        
        # åº”ç”¨å˜æ¢åˆ°å›¾åƒ2
        aligned_image2 = self.apply_transform_to_image(
            å›¾åƒ2, place_x, place_y, base_h, base_w, å¡«å……é¢œè‰²
        )
        
        # åº”ç”¨å˜æ¢åˆ°é®ç½©2
        aligned_mask2 = self.apply_transform_to_mask(
            é®ç½©2, place_x, place_y, base_h, base_w
        )
        
        # ç¡®ä¿é®ç½©è¾“å‡ºç»´åº¦æ­£ç¡®
        if len(åŸºå‡†é®ç½©.shape) == 3:
            if len(aligned_mask2.shape) == 2:
                aligned_mask2 = aligned_mask2.unsqueeze(0)
        
        print(f"è¾“å‡ºå›¾åƒå°ºå¯¸: {aligned_image2.shape}")
        print(f"è¾“å‡ºé®ç½©å°ºå¯¸: {aligned_mask2.shape}")
        
        return (aligned_image2, åŸºå‡†é®ç½©, aligned_mask2)


class ImageAlignByMaskBatch:
    """
    æ‰¹é‡ç‰ˆæœ¬ï¼šæ”¯æŒå¤šä¸ªå›¾åƒåŒæ—¶å¯¹é½
    """
    
    def __init__(self):
        self.aligner = ImageAlignByMask()
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "åŸºå‡†é®ç½©": ("MASK",),
                "é®ç½©2": ("MASK",),
                "å›¾åƒ2": ("IMAGE",),
                "å¯¹é½æ–¹å¼": (["å±…ä¸­å¯¹é½", "å·¦å¯¹é½", "å³å¯¹é½", "ä¸Šå¯¹é½", "ä¸‹å¯¹é½", 
                           "å·¦ä¸Šå¯¹é½", "å³ä¸Šå¯¹é½", "å·¦ä¸‹å¯¹é½", "å³ä¸‹å¯¹é½"], 
                          {"default": "å±…ä¸­å¯¹é½"}),
            },
            "optional": {
                "é®ç½©3": ("MASK",),
                "å›¾åƒ3": ("IMAGE",),
                "é®ç½©4": ("MASK",),
                "å›¾åƒ4": ("IMAGE",),
                "Xè½´åç§»": ("INT", {"default": 0, "min": -2048, "max": 2048, "step": 1}),
                "Yè½´åç§»": ("INT", {"default": 0, "min": -2048, "max": 2048, "step": 1}),
                "å¡«å……é¢œè‰²": (["ç™½è‰²", "é»‘è‰²", "é€æ˜"], {"default": "ç™½è‰²"}),
                "åˆå¹¶æ¨¡å¼": (["åˆ†åˆ«è¾“å‡º", "åˆå¹¶è¾“å‡º"], {"default": "åˆ†åˆ«è¾“å‡º"}),
            }
        }
    
    RETURN_TYPES = ("IMAGE", "IMAGE", "IMAGE", "MASK")
    RETURN_NAMES = ("å®šä½å›¾åƒ2", "å®šä½å›¾åƒ3", "å®šä½å›¾åƒ4", "åˆå¹¶é®ç½©")
    FUNCTION = "align_multiple_images"
    CATEGORY = "ğŸ³Pond/image"
    
    def merge_images_with_masks(self, images: List[torch.Tensor], masks: List[torch.Tensor]) -> torch.Tensor:
        """ä½¿ç”¨é®ç½©åˆå¹¶å¤šä¸ªå›¾åƒ"""
        if len(images) == 0:
            return None
            
        result = images[0].clone()
        
        for i in range(1, len(images)):
            if i < len(masks):
                mask = masks[i]
                if len(mask.shape) == 2:
                    mask = mask.unsqueeze(0).unsqueeze(-1)
                elif len(mask.shape) == 3:
                    mask = mask.unsqueeze(-1)
                
                # ä½¿ç”¨é®ç½©æ··åˆå›¾åƒ
                result = result * (1 - mask) + images[i] * mask
        
        return result
    
    def align_multiple_images(self, åŸºå‡†é®ç½©, é®ç½©2, å›¾åƒ2, å¯¹é½æ–¹å¼,
                            é®ç½©3=None, å›¾åƒ3=None, 
                            é®ç½©4=None, å›¾åƒ4=None,
                            Xè½´åç§»=0, Yè½´åç§»=0, å¡«å……é¢œè‰²="ç™½è‰²", åˆå¹¶æ¨¡å¼="åˆ†åˆ«è¾“å‡º"):
        """å¯¹é½å¤šä¸ªå›¾åƒ"""
        
        # æ”¶é›†æ‰€æœ‰éœ€è¦å¯¹é½çš„å›¾åƒå’Œé®ç½©å¯¹
        mask_image_pairs = [(é®ç½©2, å›¾åƒ2)]
        if é®ç½©3 is not None and å›¾åƒ3 is not None:
            mask_image_pairs.append((é®ç½©3, å›¾åƒ3))
        if é®ç½©4 is not None and å›¾åƒ4 is not None:
            mask_image_pairs.append((é®ç½©4, å›¾åƒ4))
        
        # å¯¹é½æ‰€æœ‰å›¾åƒ
        aligned_images = []
        aligned_masks = [åŸºå‡†é®ç½©]
        
        # å¯¹é½æ¯ä¸ªå›¾åƒ
        for mask, image in mask_image_pairs:
            aligned_img, _, aligned_mask = self.aligner.align_image_by_mask(
                åŸºå‡†é®ç½©, mask, image, å¯¹é½æ–¹å¼, Xè½´åç§», Yè½´åç§», å¡«å……é¢œè‰²
            )
            aligned_images.append(aligned_img)
            aligned_masks.append(aligned_mask)
        
        # åˆ›å»ºåˆå¹¶é®ç½©
        merged_mask = aligned_masks[0].clone()
        for mask in aligned_masks[1:]:
            merged_mask = torch.maximum(merged_mask, mask)
        
        # å¦‚æœæ˜¯åˆå¹¶è¾“å‡ºæ¨¡å¼ï¼Œåˆå¹¶æ‰€æœ‰å›¾åƒ
        if åˆå¹¶æ¨¡å¼ == "åˆå¹¶è¾“å‡º" and len(aligned_images) > 1:
            # ä½¿ç”¨å¯¹åº”çš„é®ç½©åˆå¹¶å›¾åƒ
            masks_for_merge = aligned_masks[1:]  # è·³è¿‡åŸºå‡†é®ç½©
            merged_image = self.merge_images_with_masks(aligned_images, masks_for_merge)
            # å°†ç¬¬ä¸€ä¸ªè¾“å‡ºæ›¿æ¢ä¸ºåˆå¹¶çš„å›¾åƒ
            aligned_images[0] = merged_image
        
        # å¡«å……ç©ºè¾“å‡º
        empty_image = torch.zeros_like(aligned_images[0])
        while len(aligned_images) < 3:
            aligned_images.append(empty_image)
        
        return tuple(aligned_images[:3] + [merged_mask])


NODE_CLASS_MAPPINGS = {
    "ImageAlignByMask": ImageAlignByMask,
    "ImageAlignByMaskBatch": ImageAlignByMaskBatch
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "ImageAlignByMask": "ğŸ³å›¾åƒæ‰©å±•",
    "ImageAlignByMaskBatch": "ğŸ³å›¾åƒæ‰©å±•(V2)"
}