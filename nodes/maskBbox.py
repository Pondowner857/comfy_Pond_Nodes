import torch
import numpy as np
import cv2
from typing import Tuple, List

class MaskToBBoxCropper:
    """
    ä»é®ç½©æå–è¾¹ç•Œæ¡† - è¾“å‡ºå®Œæ•´é®ç½©
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),
                "mask": ("MASK",),
            }
        }
    
    RETURN_TYPES = ("IMAGE", "MASK", "BBOX_LIST")
    RETURN_NAMES = ("preview_image", "mask", "bboxes")
    FUNCTION = "extract_bbox"
    CATEGORY = "ğŸ³Pond/bbox"
    OUTPUT_IS_LIST = (False, False, False)

    def extract_bbox(self, image, mask):
        """
        ä»é®ç½©æå–è¾¹ç•Œæ¡†
        """
        # å¤„ç†è¾“å…¥ç»´åº¦
        if image.dim() == 4:
            image_np = (image[0].cpu().numpy() * 255).astype(np.uint8)
        else:
            image_np = (image.cpu().numpy() * 255).astype(np.uint8)
        
        # å¤„ç†é®ç½©ç»´åº¦ - ä¿ç•™åŸå§‹é®ç½©
        if mask.dim() == 4:
            mask_tensor = mask[0]
            mask_np = (mask[0, 0].cpu().numpy() * 255).astype(np.uint8)
        elif mask.dim() == 3:
            mask_tensor = mask
            mask_np = (mask[0].cpu().numpy() * 255).astype(np.uint8)
        else:
            mask_tensor = mask.unsqueeze(0)
            mask_np = (mask.cpu().numpy() * 255).astype(np.uint8)
        
        # ç¡®ä¿å›¾åƒæ˜¯RGBæ ¼å¼
        if len(image_np.shape) == 2:
            image_np = cv2.cvtColor(image_np, cv2.COLOR_GRAY2RGB)
        elif image_np.shape[2] == 4:
            image_np = image_np[:, :, :3]
        
        # äºŒå€¼åŒ–é®ç½©
        _, binary_mask = cv2.threshold(mask_np, 127, 255, cv2.THRESH_BINARY)
        
        # æŸ¥æ‰¾è½®å»“
        contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        bboxes_list = []
        
        # åˆ›å»ºé¢„è§ˆå›¾åƒ
        preview_img = image_np.copy()
        colors = [(0, 255, 0), (255, 0, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255), (0, 255, 255)]
        
        # å¤„ç†æ¯ä¸ªè½®å»“
        for idx, contour in enumerate(contours):
            # è·å–è¾¹ç•Œæ¡†
            x, y, w, h = cv2.boundingRect(contour)
            
            # æ·»åŠ åˆ°åˆ—è¡¨
            bboxes_list.append([x, y, x + w, y + h])
            
            # åœ¨é¢„è§ˆå›¾ä¸Šç»˜åˆ¶è¾¹ç•Œæ¡†
            color = colors[idx % len(colors)]
            cv2.rectangle(preview_img, (x, y), (x + w, y + h), color, 2)
            # æ·»åŠ ç¼–å·æ ‡ç­¾
            cv2.putText(preview_img, f"{idx}", (x + 5, y + 20), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°è½®å»“ï¼Œè¿”å›æ•´ä¸ªåŒºåŸŸ
        if not contours:
            bboxes_list.append([0, 0, image_np.shape[1], image_np.shape[0]])
        
        # è½¬æ¢é¢„è§ˆå›¾åƒä¸ºtensor
        preview_tensor = torch.from_numpy(preview_img.astype(np.float32) / 255.0).unsqueeze(0)
        
        # è¿”å›åŸå§‹é®ç½©ï¼ˆä¸æ˜¯åˆ—è¡¨ï¼‰
        return (preview_tensor, mask_tensor, bboxes_list)


class CropByBBox:
    """
    æ ¹æ®è¾¹ç•Œæ¡†è£å‰ªå›¾åƒï¼Œæ”¯æŒå››å‘ç‹¬ç«‹æ‰©å±•å’Œç¾½åŒ–
    é»˜è®¤è£å‰ªæ‰€æœ‰bboxå¹¶åˆå¹¶åˆ°ä¸€å¼ å›¾
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),
                "bbox": ("BBOX_LIST",),
                "bbox_index": ("INT", {
                    "default": -1,
                    "min": -1,
                    "max": 99,
                    "step": 1,
                    "display": "number"
                }),
                "expand_top": ("INT", {
                    "default": 0,
                    "min": -9999,
                    "max": 9999,
                    "step": 1,
                    "display": "number"
                }),
                "expand_bottom": ("INT", {
                    "default": 0,
                    "min": -9999,
                    "max": 9999,
                    "step": 1,
                    "display": "number"
                }),
                "expand_left": ("INT", {
                    "default": 0,
                    "min": -9999,
                    "max": 9999,
                    "step": 1,
                    "display": "number"
                }),
                "expand_right": ("INT", {
                    "default": 0,
                    "min": -9999,
                    "max": 9999,
                    "step": 1,
                    "display": "number"
                }),
                "feather": ("INT", {
                    "default": 0,
                    "min": 0,
                    "max": 9999,
                    "step": 1,
                    "display": "number"
                }),
            }
        }
    
    RETURN_TYPES = ("IMAGE", "MASK", "CROP_DATA")
    RETURN_NAMES = ("cropped_image", "crop_mask", "crop_data")
    FUNCTION = "crop_image"
    CATEGORY = "ğŸ³Pond/bbox"

    def crop_image(self, image, bbox, bbox_index=-1, expand_top=0, expand_bottom=0, expand_left=0, expand_right=0, feather=0):
        """
        æ ¹æ®è¾¹ç•Œæ¡†è£å‰ªå›¾åƒ
        bbox_index = -1 æ—¶è£å‰ªæ‰€æœ‰bboxå¹¶åˆå¹¶
        bbox_index >= 0 æ—¶è£å‰ªæŒ‡å®šçš„å•ä¸ªbbox
        """
        # å¤„ç†å›¾åƒè¾“å…¥
        if image.dim() == 4:
            img_np = (image[0].cpu().numpy() * 255).astype(np.uint8)
        else:
            img_np = (image.cpu().numpy() * 255).astype(np.uint8)
        
        # ç¡®ä¿æ˜¯RGB
        if len(img_np.shape) == 2:
            img_np = cv2.cvtColor(img_np, cv2.COLOR_GRAY2RGB)
        elif img_np.shape[2] == 4:
            img_np = img_np[:, :, :3]
        
        # ç¡®ä¿bboxæ˜¯åˆ—è¡¨
        if not isinstance(bbox, list):
            bbox = [bbox]
        
        # å¦‚æœbbox_indexä¸º-1ï¼Œå¤„ç†æ‰€æœ‰bbox
        if bbox_index == -1:
            # è®¡ç®—æ‰€æœ‰bboxçš„æœ€å°å¤–æ¥çŸ©å½¢
            if len(bbox) > 0:
                min_x = min([b[0] for b in bbox])
                min_y = min([b[1] for b in bbox])
                max_x = max([b[2] for b in bbox])
                max_y = max([b[3] for b in bbox])
                
                # åº”ç”¨æ‰©å±•
                min_x = max(0, min_x - expand_left)
                min_y = max(0, min_y - expand_top)
                max_x = min(img_np.shape[1], max_x + expand_right)
                max_y = min(img_np.shape[0], max_y + expand_bottom)
                
                # ä¿å­˜è£å‰ªåæ ‡
                crop_coords = [min_x, min_y, max_x, max_y]
                
                # åˆ›å»ºåˆå¹¶çš„è£å‰ªå›¾åƒå’Œé®ç½©
                cropped = img_np[min_y:max_y, min_x:max_x].copy()
                h, w = max_y - min_y, max_x - min_x
                crop_mask = np.zeros((h, w), dtype=np.float32)
                
                # åœ¨é®ç½©ä¸­ç»˜åˆ¶æ‰€æœ‰bboxåŒºåŸŸ
                for single_bbox in bbox:
                    x1, y1, x2, y2 = single_bbox[:4]
                    # è½¬æ¢åˆ°è£å‰ªåçš„åæ ‡ç³»
                    x1 = max(0, x1 - min_x + expand_left)
                    y1 = max(0, y1 - min_y + expand_top)
                    x2 = min(w, x2 - min_x + expand_left)
                    y2 = min(h, y2 - min_y + expand_top)
                    
                    # å¡«å……è¯¥åŒºåŸŸ
                    crop_mask[y1:y2, x1:x2] = 1.0
                
                # åº”ç”¨ç¾½åŒ–åˆ°æ•´ä¸ªé®ç½©
                if feather > 0 and h > feather*2 and w > feather*2:
                    # ä½¿ç”¨è·ç¦»å˜æ¢åˆ›å»ºç¾½åŒ–
                    crop_mask_uint8 = (crop_mask * 255).astype(np.uint8)
                    dist_transform = cv2.distanceTransform(crop_mask_uint8, cv2.DIST_L2, 5)
                    if dist_transform.max() > 0:
                        crop_mask = np.minimum(dist_transform / feather, 1.0)
                    
                    # é«˜æ–¯æ¨¡ç³Šå¹³æ»‘
                    if feather > 2:
                        kernel_size = min(feather * 2 + 1, 51)
                        if kernel_size % 2 == 0:
                            kernel_size += 1
                        crop_mask = cv2.GaussianBlur(crop_mask, (kernel_size, kernel_size), feather/3)
            else:
                # æ²¡æœ‰bboxæ—¶è¿”å›æ•´ä¸ªå›¾åƒ
                cropped = img_np.copy()
                crop_mask = np.ones((img_np.shape[0], img_np.shape[1]), dtype=np.float32)
                crop_coords = [0, 0, img_np.shape[1], img_np.shape[0]]
        
        else:
            # å¤„ç†å•ä¸ªbbox
            if len(bbox) > bbox_index:
                single_bbox = bbox[bbox_index]
            else:
                single_bbox = bbox[-1] if bbox else [0, 0, img_np.shape[1], img_np.shape[0]]
            
            # è·å–åæ ‡
            try:
                x1, y1, x2, y2 = single_bbox[:4]
                x1, y1, x2, y2 = int(float(x1)), int(float(y1)), int(float(x2)), int(float(y2))
            except:
                x1, y1, x2, y2 = 0, 0, img_np.shape[1], img_np.shape[0]
            
            # åº”ç”¨æ‰©å±•
            x1 = max(0, x1 - expand_left)
            y1 = max(0, y1 - expand_top)
            x2 = min(img_np.shape[1], x2 + expand_right)
            y2 = min(img_np.shape[0], y2 + expand_bottom)
            
            # ä¿å­˜è£å‰ªåæ ‡
            crop_coords = [x1, y1, x2, y2]
            
            # è£å‰ª
            cropped = img_np[y1:y2, x1:x2].copy()
            h, w = y2 - y1, x2 - x1
            crop_mask = np.ones((h, w), dtype=np.float32)
            
            # åº”ç”¨ç¾½åŒ–
            if feather > 0 and h > feather*2 and w > feather*2:
                for y in range(h):
                    for x in range(w):
                        dist_to_edge = min(x, w - 1 - x, y, h - 1 - y)
                        if dist_to_edge < feather:
                            crop_mask[y, x] = dist_to_edge / feather
                
                if feather > 2:
                    kernel_size = min(feather * 2 + 1, 51)
                    if kernel_size % 2 == 0:
                        kernel_size += 1
                    crop_mask = cv2.GaussianBlur(crop_mask, (kernel_size, kernel_size), feather/3)
        
        # è½¬æ¢ä¸ºtensor
        cropped_tensor = torch.from_numpy(cropped.astype(np.float32) / 255.0)
        if cropped_tensor.dim() == 2:
            cropped_tensor = cropped_tensor.unsqueeze(-1).repeat(1, 1, 3)
        cropped_tensor = cropped_tensor.unsqueeze(0)
        
        mask_tensor = torch.from_numpy(crop_mask)
        if mask_tensor.dim() == 2:
            mask_tensor = mask_tensor.unsqueeze(0)
        
        return (cropped_tensor, mask_tensor, crop_coords)


# èŠ‚ç‚¹ç±»æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "MaskToBBoxCropper": MaskToBBoxCropper,
    "CropByBBox": CropByBBox,
}

# èŠ‚ç‚¹æ˜¾ç¤ºåç§°æ˜ å°„  
NODE_DISPLAY_NAME_MAPPINGS = {
    "MaskToBBoxCropper": "ğŸ³é®ç½©åˆ°bbox",
    "CropByBBox": "ğŸ³bboxè£å‰ª",
}