import torch
import torchvision.transforms.functional as TF
import numpy as np

class YoloImagePasteNode:
    """
    ä¸YOLOæ£€æµ‹èŠ‚ç‚¹é…å¥—çš„æ‹¼æ¥èŠ‚ç‚¹
    å°†å¤„ç†åçš„å›¾åƒç²˜è´´å›åŸå§‹ä½ç½®
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "original_image": ("IMAGE", {"display": "åŸå§‹å›¾åƒ"}),
                "paste_images": ("IMAGE", {"display": "ç²˜è´´å›¾åƒ"}),
                "bboxes": ("BBOXES", {"display": "è¾¹ç•Œæ¡†"}),
                "paste_mode": (["è‡ªåŠ¨åŒ¹é…", "æŒ‡å®šç´¢å¼•", "å…¨éƒ¨æ›¿æ¢"], {
                    "default": "è‡ªåŠ¨åŒ¹é…",
                    "display": "ç²˜è´´æ¨¡å¼"
                }),
                "target_index": ("INT", {
                    "default": 0, 
                    "min": 0, 
                    "max": 100, 
                    "step": 1,
                    "display": "ç›®æ ‡ç´¢å¼•"
                }),
                "blend_mode": (["è¦†ç›–", "æ··åˆ", "é®ç½©æ··åˆ"], {
                    "default": "è¦†ç›–",
                    "display": "æ··åˆæ¨¡å¼"
                }),
                "blend_alpha": ("FLOAT", {
                    "default": 1.0, 
                    "min": 0.0, 
                    "max": 1.0, 
                    "step": 0.1,
                    "display": "æ··åˆé€æ˜åº¦"
                }),
                "feather_amount": ("INT", {
                    "default": 0,
                    "min": 0,
                    "max": 50,
                    "step": 1,
                    "display": "ç¾½åŒ–ç¨‹åº¦"
                })
            },
            "optional": {
                "mask": ("MASK", {"display": "é®ç½©"})
            }
        }

    RETURN_TYPES = ("IMAGE", "MASK")
    RETURN_NAMES = ("æ‹¼æ¥å›¾åƒ", "åˆæˆé®ç½©")
    FUNCTION = "paste_images"
    CATEGORY = "ğŸ³Pond/yolo"
    DESCRIPTION = "å°†å¤„ç†åçš„å›¾åƒç²˜è´´å›YOLOæ£€æµ‹çš„åŸå§‹ä½ç½®ï¼Œæ”¯æŒå¤šç§æ··åˆæ¨¡å¼"

    def create_feathered_mask(self, height, width, bbox, feather_amount):
        """åˆ›å»ºç¾½åŒ–é®ç½©"""
        mask = np.zeros((height, width), dtype=np.float32)
        x1, y1, x2, y2 = [int(coord) for coord in bbox]
        
        # åˆ›å»ºåŸºç¡€é®ç½©
        mask[y1:y2, x1:x2] = 1.0
        
        if feather_amount > 0:
            # åº”ç”¨é«˜æ–¯æ¨¡ç³Šå®ç°ç¾½åŒ–
            import cv2
            kernel_size = feather_amount * 2 + 1
            mask = cv2.GaussianBlur(mask, (kernel_size, kernel_size), feather_amount)
        
        return mask

    def resize_and_paste(self, original_img, paste_img, bbox, blend_mode, blend_alpha, feather_amount, mask=None):
        """å°†å›¾åƒè°ƒæ•´å¤§å°å¹¶ç²˜è´´åˆ°æŒ‡å®šä½ç½®"""
        height, width = original_img.shape[1], original_img.shape[2]
        
        # è§£æè¾¹ç•Œæ¡†
        x1, y1, x2, y2 = [int(coord) for coord in bbox]
        
        # ç¡®ä¿åæ ‡åœ¨å›¾åƒèŒƒå›´å†…
        x1 = max(0, min(x1, width))
        y1 = max(0, min(y1, height))
        x2 = max(x1, min(x2, width))
        y2 = max(y1, min(y2, height))
        
        target_width = x2 - x1
        target_height = y2 - y1
        
        if target_width <= 0 or target_height <= 0:
            print(f"è­¦å‘Š: æ— æ•ˆçš„ç²˜è´´åŒºåŸŸ [{x1},{y1},{x2},{y2}]")
            return original_img, torch.zeros((height, width), dtype=torch.float32)
        
        # è°ƒæ•´ç²˜è´´å›¾åƒå¤§å°
        paste_tensor = paste_img.permute(2, 0, 1)  # HWC -> CHW
        resized_paste = TF.resize(
            paste_tensor, 
            [target_height, target_width],
            interpolation=TF.InterpolationMode.BICUBIC,
            antialias=True
        ).permute(1, 2, 0)  # CHW -> HWC
        
        # æ‰§è¡Œç²˜è´´
        result_img = original_img.clone()
        
        if blend_mode == "è¦†ç›–":
            result_img[y1:y2, x1:x2, :] = resized_paste
        elif blend_mode == "æ··åˆ":
            original_region = result_img[y1:y2, x1:x2, :]
            blended = original_region * (1 - blend_alpha) + resized_paste * blend_alpha
            result_img[y1:y2, x1:x2, :] = blended
        elif blend_mode == "é®ç½©æ··åˆ":
            # åˆ›å»ºç¾½åŒ–é®ç½©
            feather_mask = self.create_feathered_mask(height, width, bbox, feather_amount)
            feather_mask_tensor = torch.from_numpy(feather_mask).float()
            
            # åº”ç”¨é®ç½©æ··åˆ
            for c in range(3):  # RGBé€šé“
                result_img[:, :, c] = original_img[:, :, c] * (1 - feather_mask_tensor) + \
                                     result_img[:, :, c] * feather_mask_tensor
        
        # åˆ›å»ºè¾“å‡ºé®ç½©
        output_mask = np.zeros((height, width), dtype=np.float32)
        output_mask[y1:y2, x1:x2] = 1.0
        output_mask_tensor = torch.from_numpy(output_mask).float()
        
        return result_img, output_mask_tensor

    def paste_images(self, original_image, paste_images, bboxes, paste_mode, 
                    target_index, blend_mode, blend_alpha, feather_amount, mask=None):
        """æ‰§è¡Œå›¾åƒæ‹¼æ¥"""
        # ç¡®ä¿è¾“å…¥æ˜¯4ç»´å¼ é‡
        if len(original_image.shape) == 3:
            original_image = original_image.unsqueeze(0)
        if len(paste_images.shape) == 3:
            paste_images = paste_images.unsqueeze(0)
        
        batch_size = original_image.shape[0]
        num_paste_images = paste_images.shape[0]
        
        # å¤„ç†è¾¹ç•Œæ¡†æ•°æ®
        if isinstance(bboxes, torch.Tensor):
            bboxes_list = bboxes.tolist()
        else:
            bboxes_list = bboxes
        
        num_bboxes = len(bboxes_list)
        
        print(f"åŸå›¾æ‰¹æ¬¡: {batch_size}, ç²˜è´´å›¾åƒ: {num_paste_images}, è¾¹ç•Œæ¡†: {num_bboxes}")
        
        try:
            result_images = []
            result_masks = []
            
            for b in range(batch_size):
                current_img = original_image[b]
                current_mask = torch.zeros((current_img.shape[1], current_img.shape[2]), dtype=torch.float32)
                
                if paste_mode == "æŒ‡å®šç´¢å¼•":
                    # æŒ‡å®šç´¢å¼•æ¨¡å¼ï¼šåªç²˜è´´æŒ‡å®šç´¢å¼•çš„å›¾åƒ
                    if target_index < num_paste_images and target_index < num_bboxes:
                        paste_img = paste_images[target_index]
                        bbox = bboxes_list[target_index]
                        current_img, paste_mask = self.resize_and_paste(
                            current_img, paste_img, bbox, blend_mode, blend_alpha, feather_amount, mask
                        )
                        current_mask = torch.maximum(current_mask, paste_mask)
                        print(f"ä½¿ç”¨æŒ‡å®šç´¢å¼• {target_index} è¿›è¡Œç²˜è´´")
                    else:
                        print(f"è­¦å‘Š: æŒ‡å®šç´¢å¼• {target_index} è¶…å‡ºèŒƒå›´")
                
                elif paste_mode == "å…¨éƒ¨æ›¿æ¢":
                    # å…¨éƒ¨æ›¿æ¢æ¨¡å¼ï¼šæ›¿æ¢æ‰€æœ‰æ£€æµ‹åˆ°çš„åŒºåŸŸ
                    max_items = min(num_paste_images, num_bboxes)
                    
                    # å¦‚æœç²˜è´´å›¾åƒå°‘äºè¾¹ç•Œæ¡†ï¼Œå¾ªç¯ä½¿ç”¨
                    for i in range(num_bboxes):
                        paste_idx = i % num_paste_images
                        paste_img = paste_images[paste_idx]
                        bbox = bboxes_list[i]
                        current_img, paste_mask = self.resize_and_paste(
                            current_img, paste_img, bbox, blend_mode, blend_alpha, feather_amount, mask
                        )
                        current_mask = torch.maximum(current_mask, paste_mask)
                    
                    print(f"å…¨éƒ¨æ›¿æ¢æ¨¡å¼: ç²˜è´´äº† {num_bboxes} ä¸ªåŒºåŸŸ")
                
                else:  # è‡ªåŠ¨åŒ¹é…æ¨¡å¼
                    # è‡ªåŠ¨åŒ¹é…ï¼šæŒ‰é¡ºåºç²˜è´´æ‰€æœ‰å¯ç”¨çš„å›¾åƒ
                    max_items = min(num_paste_images, num_bboxes)
                    
                    for i in range(max_items):
                        paste_img = paste_images[i]
                        bbox = bboxes_list[i]
                        current_img, paste_mask = self.resize_and_paste(
                            current_img, paste_img, bbox, blend_mode, blend_alpha, feather_amount, mask
                        )
                        current_mask = torch.maximum(current_mask, paste_mask)
                    
                    print(f"è‡ªåŠ¨åŒ¹é…æ¨¡å¼: ç²˜è´´äº† {max_items} ä¸ªå›¾åƒ")
                
                result_images.append(current_img.unsqueeze(0))
                result_masks.append(current_mask.unsqueeze(0).unsqueeze(-1))
            
            # åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡
            final_result = torch.cat(result_images, dim=0)
            final_mask = torch.cat(result_masks, dim=0)
            
            return (final_result, final_mask)
            
        except Exception as e:
            print(f"å›¾åƒæ‹¼æ¥è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            # è¿”å›åŸå›¾ä½œä¸ºfallback
            empty_mask = torch.zeros((batch_size, original_image.shape[1], original_image.shape[2], 1), dtype=torch.float32)
            return (original_image, empty_mask)

# èŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "YoloImagePasteNode": YoloImagePasteNode
}

# èŠ‚ç‚¹æ˜¾ç¤ºåç§°æ˜ å°„
NODE_DISPLAY_NAME_MAPPINGS = {
    "YoloImagePasteNode": "ğŸ³YOLOå›¾åƒæ‹¼æ¥"
}