import torch
import torchvision.transforms.functional as TF
import numpy as np

class YoloImagePasteNode:
    """
    ä¸YOLOæ£€æµ‹èŠ‚ç‚¹é…å¥—çš„æ‹¼æ¥èŠ‚ç‚¹
    å°†å¤„ç†åçš„å›¾åƒç²˜è´´å›åŸå§‹ä½ç½®
    æ”¯æŒåˆ—è¡¨è¾“å…¥ï¼Œè¾“å‡ºå•å¼ åˆæˆå›¾åƒ
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "original_image": ("IMAGE", {"display": "åŸå§‹å›¾åƒ"}),
                "paste_images": ("IMAGE", {"display": "ç²˜è´´å›¾åƒåˆ—è¡¨"}),
                "bboxes": ("BBOXES", {"display": "è¾¹ç•Œæ¡†"}),
                "paste_mode": (["å…¨éƒ¨ç²˜è´´", "æŒ‡å®šç´¢å¼•", "å¾ªç¯ä½¿ç”¨"], {
                    "default": "å…¨éƒ¨ç²˜è´´",
                    "display": "ç²˜è´´æ¨¡å¼"
                }),
                "target_index": ("INT", {
                    "default": 0, 
                    "min": 0, 
                    "max": 100, 
                    "step": 1,
                    "display": "ç›®æ ‡ç´¢å¼•"
                }),
                "blend_mode": (["è¦†ç›–", "æ··åˆ", "é®ç½©æ··åˆ"], {
                    "default": "è¦†ç›–",
                    "display": "æ··åˆæ¨¡å¼"
                }),
                "blend_alpha": ("FLOAT", {
                    "default": 1.0, 
                    "min": 0.0, 
                    "max": 1.0, 
                    "step": 0.1,
                    "display": "æ··åˆé€æ˜åº¦"
                }),
                "feather_amount": ("INT", {
                    "default": 0,
                    "min": 0,
                    "max": 50,
                    "step": 1,
                    "display": "ç¾½åŒ–ç¨‹åº¦"
                })
            },
            "optional": {
                "mask": ("MASK", {"display": "é®ç½©"})
            }
        }

    RETURN_TYPES = ("IMAGE", "MASK")
    RETURN_NAMES = ("æ‹¼æ¥å›¾åƒ", "åˆæˆé®ç½©")
    INPUT_IS_LIST = {"paste_images": True}  # æ ‡è®°paste_imagesæ¥æ”¶åˆ—è¡¨
    FUNCTION = "paste_images"
    CATEGORY = "ğŸ³Pond/yolo"
    DESCRIPTION = "å°†å¤„ç†åçš„å›¾åƒåˆ—è¡¨ç²˜è´´å›YOLOæ£€æµ‹çš„åŸå§‹ä½ç½®ï¼Œè¾“å‡ºå•å¼ åˆæˆå›¾åƒã€‚æ”¯æŒæ¥æ”¶è£å‰ªèŠ‚ç‚¹çš„åˆ—è¡¨è¾“å‡ºã€‚"

    def create_feathered_mask(self, height, width, bbox, feather_amount):
        """åˆ›å»ºç¾½åŒ–é®ç½©"""
        mask = np.zeros((height, width), dtype=np.float32)
        x1, y1, x2, y2 = [int(coord) for coord in bbox]
        
        # ç¡®ä¿åæ ‡åœ¨æœ‰æ•ˆèŒƒå›´å†…
        x1 = max(0, min(x1, width))
        y1 = max(0, min(y1, height))
        x2 = max(x1, min(x2, width))
        y2 = max(y1, min(y2, height))
        
        if x2 > x1 and y2 > y1:
            # åˆ›å»ºåŸºç¡€é®ç½©
            mask[y1:y2, x1:x2] = 1.0
            
            if feather_amount > 0:
                # åº”ç”¨é«˜æ–¯æ¨¡ç³Šå®ç°ç¾½åŒ–
                try:
                    import cv2
                    kernel_size = feather_amount * 2 + 1
                    mask = cv2.GaussianBlur(mask, (kernel_size, kernel_size), feather_amount)
                except ImportError:
                    print("è­¦å‘Š: æœªå®‰è£…OpenCVï¼Œæ— æ³•åº”ç”¨ç¾½åŒ–æ•ˆæœ")
        
        return mask

    def resize_and_paste(self, original_img, paste_img, bbox, blend_mode, blend_alpha, feather_amount, mask=None):
        """å°†å›¾åƒè°ƒæ•´å¤§å°å¹¶ç²˜è´´åˆ°æŒ‡å®šä½ç½®"""
        # ç¡®ä¿è¾“å…¥å›¾åƒç»´åº¦æ­£ç¡®
        if len(original_img.shape) == 4:
            original_img = original_img[0]
        if len(paste_img.shape) == 4:
            paste_img = paste_img[0]
        
        # è·å–åŸå›¾å°ºå¯¸
        height, width = original_img.shape[:2]
        
        # è§£æè¾¹ç•Œæ¡†
        x1, y1, x2, y2 = [int(coord) for coord in bbox]
        
        # ç¡®ä¿åæ ‡åœ¨å›¾åƒèŒƒå›´å†…
        x1 = max(0, min(x1, width))
        y1 = max(0, min(y1, height))
        x2 = max(x1, min(x2, width))
        y2 = max(y1, min(y2, height))
        
        target_width = x2 - x1
        target_height = y2 - y1
        
        if target_width <= 0 or target_height <= 0:
            print(f"è­¦å‘Š: æ— æ•ˆçš„ç²˜è´´åŒºåŸŸ [{x1},{y1},{x2},{y2}]")
            return original_img, torch.zeros((height, width), dtype=torch.float32)
        
        # è°ƒæ•´ç²˜è´´å›¾åƒå¤§å°
        paste_tensor = paste_img.permute(2, 0, 1)  # HWC -> CHW
        resized_paste = TF.resize(
            paste_tensor, 
            [target_height, target_width],
            interpolation=TF.InterpolationMode.BICUBIC,
            antialias=True
        ).permute(1, 2, 0)  # CHW -> HWC
        
        # æ‰§è¡Œç²˜è´´
        result_img = original_img.clone()
        
        if blend_mode == "è¦†ç›–":
            result_img[y1:y2, x1:x2, :] = resized_paste
        elif blend_mode == "æ··åˆ":
            original_region = result_img[y1:y2, x1:x2, :]
            blended = original_region * (1 - blend_alpha) + resized_paste * blend_alpha
            result_img[y1:y2, x1:x2, :] = blended
        elif blend_mode == "é®ç½©æ··åˆ":
            # åˆ›å»ºç¾½åŒ–é®ç½©
            feather_mask = self.create_feathered_mask(height, width, bbox, feather_amount)
            feather_mask_tensor = torch.from_numpy(feather_mask).float()
            
            # åˆ›å»ºä¸´æ—¶å›¾åƒç”¨äºæ··åˆ
            temp_img = original_img.clone()
            temp_img[y1:y2, x1:x2, :] = resized_paste
            
            # åº”ç”¨é®ç½©æ··åˆ
            for c in range(3):  # RGBé€šé“
                result_img[:, :, c] = original_img[:, :, c] * (1 - feather_mask_tensor) + \
                                     temp_img[:, :, c] * feather_mask_tensor
        
        # åˆ›å»ºè¾“å‡ºé®ç½©
        output_mask = np.zeros((height, width), dtype=np.float32)
        output_mask[y1:y2, x1:x2] = 1.0
        output_mask_tensor = torch.from_numpy(output_mask).float()
        
        return result_img, output_mask_tensor

    def paste_images(self, original_image, paste_images, bboxes, paste_mode, 
                    target_index, blend_mode, blend_alpha, feather_amount, mask=None):
        """æ‰§è¡Œå›¾åƒæ‹¼æ¥ - å°†å¤šä¸ªå›¾åƒç²˜è´´åˆ°ä¸€å¼ åŸå›¾ä¸Š"""
        
        # å¤„ç†åŸå§‹å›¾åƒè¾“å…¥ï¼ˆå¯èƒ½æ˜¯åˆ—è¡¨ï¼‰
        if isinstance(original_image, list):
            # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œä½¿ç”¨ç¬¬ä¸€å¼ å›¾åƒ
            original_image = original_image[0]
        
        # ç¡®ä¿åŸå§‹å›¾åƒæ˜¯4ç»´å¼ é‡
        if len(original_image.shape) == 3:
            original_image = original_image.unsqueeze(0)
        
        # ä½¿ç”¨ç¬¬ä¸€å¼ åŸå›¾ä½œä¸ºåŸºåº•
        base_image = original_image[0].clone()
        height, width = base_image.shape[:2]
        
        # åˆå§‹åŒ–ç´¯ç§¯é®ç½©
        cumulative_mask = torch.zeros((height, width), dtype=torch.float32)
        
        # å¤„ç†ç²˜è´´å›¾åƒåˆ—è¡¨
        if not isinstance(paste_images, list):
            paste_images = [paste_images]
        
        # éªŒè¯è¾“å…¥
        if not paste_images:
            print("é”™è¯¯ï¼šæ²¡æœ‰æä¾›ç²˜è´´å›¾åƒ")
            empty_mask = torch.zeros((1, original_image.shape[1], original_image.shape[2]), dtype=torch.float32)
            return (original_image.unsqueeze(0) if len(original_image.shape) == 3 else original_image[:1], empty_mask)
        
        # å¤„ç†è¾¹ç•Œæ¡†æ•°æ®
        if isinstance(bboxes, torch.Tensor):
            bboxes_list = bboxes.tolist()
        else:
            bboxes_list = bboxes
        
        num_paste_images = len(paste_images)
        num_bboxes = len(bboxes_list)
        
        print(f"ç²˜è´´å›¾åƒæ•°é‡: {num_paste_images}, è¾¹ç•Œæ¡†æ•°é‡: {num_bboxes}")
        
        try:
            if paste_mode == "æŒ‡å®šç´¢å¼•":
                # æŒ‡å®šç´¢å¼•æ¨¡å¼ï¼šåªç²˜è´´æŒ‡å®šç´¢å¼•çš„å›¾åƒ
                if target_index < num_paste_images and target_index < num_bboxes:
                    paste_img = paste_images[target_index]
                    # ç¡®ä¿å›¾åƒç»´åº¦æ­£ç¡®
                    if isinstance(paste_img, torch.Tensor) and len(paste_img.shape) == 4:
                        paste_img = paste_img[0]
                    bbox = bboxes_list[target_index]
                    base_image, paste_mask = self.resize_and_paste(
                        base_image, paste_img, bbox, blend_mode, blend_alpha, feather_amount, mask
                    )
                    cumulative_mask = torch.maximum(cumulative_mask, paste_mask)
                    print(f"ä½¿ç”¨æŒ‡å®šç´¢å¼• {target_index} è¿›è¡Œç²˜è´´")
                else:
                    print(f"è­¦å‘Š: æŒ‡å®šç´¢å¼• {target_index} è¶…å‡ºèŒƒå›´")
            
            elif paste_mode == "å¾ªç¯ä½¿ç”¨":
                # å¾ªç¯ä½¿ç”¨æ¨¡å¼ï¼šå¦‚æœå›¾åƒå°‘äºè¾¹ç•Œæ¡†ï¼Œå¾ªç¯ä½¿ç”¨å›¾åƒ
                for i in range(num_bboxes):
                    paste_idx = i % num_paste_images
                    paste_img = paste_images[paste_idx]
                    # ç¡®ä¿å›¾åƒç»´åº¦æ­£ç¡®
                    if isinstance(paste_img, torch.Tensor) and len(paste_img.shape) == 4:
                        paste_img = paste_img[0]
                    bbox = bboxes_list[i]
                    base_image, paste_mask = self.resize_and_paste(
                        base_image, paste_img, bbox, blend_mode, blend_alpha, feather_amount, mask
                    )
                    cumulative_mask = torch.maximum(cumulative_mask, paste_mask)
                print(f"å¾ªç¯ä½¿ç”¨æ¨¡å¼: ç²˜è´´äº† {num_bboxes} ä¸ªåŒºåŸŸ")
            
            else:  # å…¨éƒ¨ç²˜è´´æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰
                # å…¨éƒ¨ç²˜è´´ï¼šæŒ‰é¡ºåºç²˜è´´æ‰€æœ‰å¯ç”¨çš„å›¾åƒ
                max_items = min(num_paste_images, num_bboxes)
                
                for i in range(max_items):
                    paste_img = paste_images[i]
                    # ç¡®ä¿å›¾åƒç»´åº¦æ­£ç¡®
                    if isinstance(paste_img, torch.Tensor) and len(paste_img.shape) == 4:
                        paste_img = paste_img[0]
                    bbox = bboxes_list[i]
                    base_image, paste_mask = self.resize_and_paste(
                        base_image, paste_img, bbox, blend_mode, blend_alpha, feather_amount, mask
                    )
                    cumulative_mask = torch.maximum(cumulative_mask, paste_mask)
                
                print(f"å…¨éƒ¨ç²˜è´´æ¨¡å¼: ç²˜è´´äº† {max_items} ä¸ªå›¾åƒ")
                
                # å¦‚æœè¾¹ç•Œæ¡†å¤šäºå›¾åƒï¼Œç»™å‡ºæç¤º
                if num_bboxes > num_paste_images:
                    print(f"æç¤º: æœ‰ {num_bboxes - num_paste_images} ä¸ªè¾¹ç•Œæ¡†æ²¡æœ‰å¯¹åº”çš„ç²˜è´´å›¾åƒ")
                elif num_paste_images > num_bboxes:
                    print(f"æç¤º: æœ‰ {num_paste_images - num_bboxes} ä¸ªç²˜è´´å›¾åƒæ²¡æœ‰ä½¿ç”¨")
            
            # æ·»åŠ æ‰¹æ¬¡ç»´åº¦å¹¶è¿”å›å•å¼ å›¾åƒ
            final_image = base_image.unsqueeze(0)
            # MASKæ ¼å¼åº”è¯¥æ˜¯ (batch, height, width)ï¼Œä¸éœ€è¦é€šé“ç»´åº¦
            final_mask = cumulative_mask.unsqueeze(0)
            
            return (final_image, final_mask)
            
        except Exception as e:
            print(f"å›¾åƒæ‹¼æ¥è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            
            # è¿”å›åŸå›¾ä½œä¸ºfallback
            empty_mask = torch.zeros((1, height, width), dtype=torch.float32)
            # ç¡®ä¿è¿”å›çš„æ˜¯tensorè€Œä¸æ˜¯åˆ—è¡¨
            if isinstance(original_image, list):
                return (original_image[0].unsqueeze(0) if len(original_image[0].shape) == 3 else original_image[0], empty_mask)
            else:
                return (original_image[:1], empty_mask)

# èŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "YoloImagePasteNode": YoloImagePasteNode
}

# èŠ‚ç‚¹æ˜¾ç¤ºåç§°æ˜ å°„
NODE_DISPLAY_NAME_MAPPINGS = {
    "YoloImagePasteNode": "ğŸ³YOLOå›¾åƒæ‹¼æ¥"
}