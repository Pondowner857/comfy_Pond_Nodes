import torch
import torchvision.transforms.functional as TF
import numpy as np

class YoloImagePasteNode:
    """
    ä¸YOLOæ£€æµ‹èŠ‚ç‚¹é…å¥—çš„æ‹¼æ¥èŠ‚ç‚¹
    å°†å¤„ç†åçš„å›¾åƒç²˜è´´å›åŸå§‹ä½ç½®
    æ”¯æŒåˆ—è¡¨è¾“å…¥ï¼Œè¾“å‡ºå•å¼ åˆæˆå›¾åƒ
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "original_image": ("IMAGE", {"display": "åŸå§‹å›¾åƒ"}),
                "paste_images": ("IMAGE", {"display": "ç²˜è´´å›¾åƒåˆ—è¡¨"}),
                "bboxes": ("BBOXES", {"display": "è¾¹ç•Œæ¡†"}),
                "paste_mode": (["å…¨éƒ¨ç²˜è´´", "æŒ‡å®šç´¢å¼•", "å¾ªç¯ä½¿ç”¨"], {
                    "default": "å…¨éƒ¨ç²˜è´´",
                    "display": "ç²˜è´´æ¨¡å¼"
                }),
                "target_index": ("INT", {
                    "default": 0, 
                    "min": 0, 
                    "max": 100, 
                    "step": 1,
                    "display": "ç›®æ ‡ç´¢å¼•"
                }),
                "blend_mode": (["ç¾½åŒ–æ··åˆ", "è¦†ç›–", "æ™®é€šæ··åˆ"], {
                    "default": "ç¾½åŒ–æ··åˆ",
                    "display": "æ··åˆæ¨¡å¼"
                }),
                "feather_amount": ("INT", {
                    "default": 20,
                    "min": 0,
                    "max": 100,
                    "step": 5,
                    "display": "ç¾½åŒ–ç¨‹åº¦"
                }),
                "color_match": ("BOOLEAN", {
                    "default": True,
                    "display": "é¢œè‰²åŒ¹é…"
                })
            }
        }

    RETURN_TYPES = ("IMAGE", "MASK")
    RETURN_NAMES = ("æ‹¼æ¥å›¾åƒ", "åˆæˆé®ç½©")
    INPUT_IS_LIST = {"paste_images": True}  # æ ‡è®°paste_imagesæ¥æ”¶åˆ—è¡¨
    FUNCTION = "paste_images"
    CATEGORY = "ğŸ³Pond/yolo"
    DESCRIPTION = "å°†å¤„ç†åçš„å›¾åƒåˆ—è¡¨ç²˜è´´å›YOLOæ£€æµ‹çš„åŸå§‹ä½ç½®ï¼Œæ”¯æŒç¾½åŒ–æ··åˆé¿å…æ˜æ˜¾è¾¹ç¼˜ã€‚"

    def create_feather_mask(self, height, width, bbox, feather_size):
        """åˆ›å»ºå¸¦ç¾½åŒ–è¾¹ç¼˜çš„é®ç½©"""
        x1, y1, x2, y2 = bbox
        
        # åˆ›å»ºåŸºç¡€é®ç½©
        mask = torch.zeros((height, width), dtype=torch.float32)
        
        # è®¡ç®—å†…éƒ¨åŒºåŸŸï¼ˆå®Œå…¨ä¸é€æ˜ï¼‰
        inner_x1 = x1 + feather_size
        inner_y1 = y1 + feather_size
        inner_x2 = x2 - feather_size
        inner_y2 = y2 - feather_size
        
        # ç¡®ä¿å†…éƒ¨åŒºåŸŸæœ‰æ•ˆ
        if inner_x2 > inner_x1 and inner_y2 > inner_y1:
            mask[inner_y1:inner_y2, inner_x1:inner_x2] = 1.0
        
        # åˆ›å»ºæ¸å˜è¾¹ç¼˜
        if feather_size > 0:
            # é¡¶éƒ¨è¾¹ç¼˜
            for i in range(feather_size):
                alpha = i / feather_size
                y = y1 + i
                if y < height and inner_x2 > inner_x1:
                    mask[y, inner_x1:inner_x2] = alpha
            
            # åº•éƒ¨è¾¹ç¼˜
            for i in range(feather_size):
                alpha = i / feather_size
                y = y2 - i - 1
                if y >= 0 and inner_x2 > inner_x1:
                    mask[y, inner_x1:inner_x2] = alpha
            
            # å·¦ä¾§è¾¹ç¼˜
            for i in range(feather_size):
                alpha = i / feather_size
                x = x1 + i
                if x < width:
                    mask[y1:y2, x] = alpha
            
            # å³ä¾§è¾¹ç¼˜
            for i in range(feather_size):
                alpha = i / feather_size
                x = x2 - i - 1
                if x >= 0:
                    mask[y1:y2, x] = alpha
            
            # è§’è½å¤„ç† - ä½¿ç”¨å¾„å‘æ¸å˜
            corners = [
                (x1, y1, inner_x1, inner_y1),  # å·¦ä¸Š
                (inner_x2, y1, x2, inner_y1),   # å³ä¸Š
                (x1, inner_y2, inner_x1, y2),   # å·¦ä¸‹
                (inner_x2, inner_y2, x2, y2)    # å³ä¸‹
            ]
            
            for cx1, cy1, cx2, cy2 in corners:
                for y in range(max(0, cy1), min(height, cy2)):
                    for x in range(max(0, cx1), min(width, cx2)):
                        # è®¡ç®—åˆ°è§’è½çš„è·ç¦»
                        if cx1 == x1:  # å·¦ä¾§è§’è½
                            dx = x - cx2
                        else:  # å³ä¾§è§’è½
                            dx = cx1 - x
                        
                        if cy1 == y1:  # ä¸Šä¾§è§’è½
                            dy = y - cy2
                        else:  # ä¸‹ä¾§è§’è½
                            dy = cy1 - y
                        
                        # ä½¿ç”¨æ¬§å‡ é‡Œå¾—è·ç¦»
                        dist = (dx * dx + dy * dy) ** 0.5
                        alpha = min(1.0, dist / feather_size)
                        mask[y, x] = alpha
        
        return mask

    def color_match_region(self, source, target, mask):
        """åŒ¹é…æºå›¾åƒå’Œç›®æ ‡å›¾åƒåœ¨é®ç½©åŒºåŸŸçš„é¢œè‰²"""
        # è®¡ç®—é®ç½©åŒºåŸŸçš„å¹³å‡é¢œè‰²
        mask_3d = mask.unsqueeze(-1).expand(-1, -1, 3)
        
        # è®¡ç®—åŸå›¾åœ¨é®ç½©åŒºåŸŸçš„å¹³å‡é¢œè‰²
        if mask.sum() > 0:
            target_mean = (target * mask_3d).sum(dim=[0, 1]) / mask_3d.sum(dim=[0, 1])
            source_mean = (source * mask_3d).sum(dim=[0, 1]) / mask_3d.sum(dim=[0, 1])
            
            # è®¡ç®—é¢œè‰²åç§»
            color_shift = target_mean - source_mean
            
            # åº”ç”¨é¢œè‰²åç§»
            adjusted_source = source + color_shift.unsqueeze(0).unsqueeze(0)
            adjusted_source = torch.clamp(adjusted_source, 0, 1)
            
            return adjusted_source
        
        return source

    def gaussian_blur_mask(self, mask, kernel_size):
        """å¯¹é®ç½©åº”ç”¨é«˜æ–¯æ¨¡ç³Š"""
        if kernel_size <= 1:
            return mask
        
        # ç¡®ä¿kernel_sizeæ˜¯å¥‡æ•°
        kernel_size = kernel_size if kernel_size % 2 == 1 else kernel_size + 1
        
        # æ·»åŠ æ‰¹æ¬¡å’Œé€šé“ç»´åº¦
        mask_4d = mask.unsqueeze(0).unsqueeze(0)
        
        # åº”ç”¨é«˜æ–¯æ¨¡ç³Š
        blurred = TF.gaussian_blur(mask_4d, kernel_size=kernel_size)
        
        # ç§»é™¤æ·»åŠ çš„ç»´åº¦
        return blurred.squeeze(0).squeeze(0)

    def parse_bboxes(self, bboxes):
        """è§£æå„ç§æ ¼å¼çš„è¾¹ç•Œæ¡†æ•°æ®"""
        bboxes_list = []
        
        #print(f"è§£æè¾¹ç•Œæ¡†ï¼ŒåŸå§‹ç±»å‹: {type(bboxes)}")
        
        # å¤„ç†åµŒå¥—åˆ—è¡¨çš„æƒ…å†µ
        if isinstance(bboxes, list):
            if len(bboxes) == 1 and isinstance(bboxes[0], list):
                # [[bbox1, bbox2, ...]] æ ¼å¼
                first_elem = bboxes[0]
                if all(isinstance(item, (list, tuple)) and len(item) == 4 for item in first_elem):
                    bboxes_list = first_elem
                    #print(f"è§£åŒ…è¾¹ç•Œæ¡†åˆ—è¡¨ï¼Œå¾—åˆ° {len(bboxes_list)} ä¸ªè¾¹ç•Œæ¡†")
                else:
                    bboxes_list = bboxes
            else:
                # ç›´æ¥æ˜¯è¾¹ç•Œæ¡†åˆ—è¡¨
                for bbox in bboxes:
                    if isinstance(bbox, (list, tuple)) and len(bbox) == 4:
                        bboxes_list.append(list(bbox))
                    elif isinstance(bbox, torch.Tensor):
                        bboxes_list.append(bbox.tolist())
        elif isinstance(bboxes, torch.Tensor):
            if bboxes.dim() == 2:
                bboxes_list = bboxes.tolist()
            elif bboxes.dim() == 1:
                bboxes_list = [bboxes.tolist()]
        
        #print(f"è§£æåå¾—åˆ° {len(bboxes_list)} ä¸ªè¾¹ç•Œæ¡†")
        return bboxes_list

    def paste_single_image(self, base_img, paste_img, bbox, blend_mode, feather_amount, color_match):
        """å°†å•ä¸ªå›¾åƒç²˜è´´åˆ°æŒ‡å®šä½ç½®"""
        # ç¡®ä¿è¾“å…¥æ˜¯3Då¼ é‡
        if len(base_img.shape) == 4:
            base_img = base_img[0]
        if len(paste_img.shape) == 4:
            paste_img = paste_img[0]
        
        # è·å–å°ºå¯¸
        h, w, _ = base_img.shape
        
        # è§£æè¾¹ç•Œæ¡†
        x1, y1, x2, y2 = [int(coord) for coord in bbox]
        
        # ç¡®ä¿åæ ‡åœ¨æœ‰æ•ˆèŒƒå›´å†…
        x1 = max(0, min(x1, w))
        y1 = max(0, min(y1, h))
        x2 = max(0, min(x2, w))
        y2 = max(0, min(y2, h))
        
        if x2 <= x1 or y2 <= y1:
            #print(f"æ— æ•ˆçš„è¾¹ç•Œæ¡†: [{x1},{y1},{x2},{y2}]")
            return base_img
        
        target_height = y2 - y1
        target_width = x2 - x1
        
        #print(f"ç²˜è´´åˆ°åŒºåŸŸ: [{x1},{y1},{x2},{y2}] (å°ºå¯¸: {target_width}x{target_height})")
        
        # è°ƒæ•´ç²˜è´´å›¾åƒå¤§å°
        paste_tensor = paste_img.permute(2, 0, 1)  # HWC -> CHW
        resized_paste = TF.resize(
            paste_tensor,
            [target_height, target_width],
            interpolation=TF.InterpolationMode.BILINEAR,
            antialias=True
        ).permute(1, 2, 0)  # CHW -> HWC
        
        # ç¡®ä¿è®¾å¤‡å’Œæ•°æ®ç±»å‹ä¸€è‡´
        resized_paste = resized_paste.to(device=base_img.device, dtype=base_img.dtype)
        
        # é¢œè‰²åŒ¹é…
        if color_match and blend_mode != "è¦†ç›–":
            # è·å–è¾¹ç•ŒåŒºåŸŸç”¨äºé¢œè‰²åŒ¹é…
            border_size = min(20, min(target_width, target_height) // 4)
            if border_size > 0:
                # åˆ›å»ºè¾¹ç•Œé®ç½©
                border_mask = torch.ones((target_height, target_width), device=base_img.device)
                if target_height > 2 * border_size and target_width > 2 * border_size:
                    border_mask[border_size:-border_size, border_size:-border_size] = 0
                
                # åœ¨è¾¹ç•ŒåŒºåŸŸè¿›è¡Œé¢œè‰²åŒ¹é…
                original_region = base_img[y1:y2, x1:x2, :]
                resized_paste = self.color_match_region(resized_paste, original_region, border_mask)
        
        # æ‰§è¡Œç²˜è´´
        if blend_mode == "è¦†ç›–":
            base_img[y1:y2, x1:x2, :] = resized_paste
        elif blend_mode == "æ™®é€šæ··åˆ":
            # ç®€å•çš„alphaæ··åˆ
            alpha = 0.8
            original_region = base_img[y1:y2, x1:x2, :].clone()
            base_img[y1:y2, x1:x2, :] = original_region * (1 - alpha) + resized_paste * alpha
        else:  # ç¾½åŒ–æ··åˆ
            # åˆ›å»ºç¾½åŒ–é®ç½©
            feather_mask = self.create_feather_mask(h, w, [x1, y1, x2, y2], feather_amount)
            
            # åº”ç”¨é¢å¤–çš„é«˜æ–¯æ¨¡ç³Šä½¿è¿‡æ¸¡æ›´å¹³æ»‘
            if feather_amount > 0:
                blur_size = max(3, feather_amount // 2)
                feather_mask = self.gaussian_blur_mask(feather_mask, blur_size)
            
            # æå–é®ç½©åŒºåŸŸ
            mask_region = feather_mask[y1:y2, x1:x2]
            mask_region_3d = mask_region.unsqueeze(-1).expand(-1, -1, 3)
            
            # åº”ç”¨ç¾½åŒ–æ··åˆ
            original_region = base_img[y1:y2, x1:x2, :]
            base_img[y1:y2, x1:x2, :] = original_region * (1 - mask_region_3d) + resized_paste * mask_region_3d
        
        return base_img

    def paste_images(self, original_image, paste_images, bboxes, paste_mode, 
                    target_index, blend_mode, feather_amount, color_match):
        """æ‰§è¡Œå›¾åƒæ‹¼æ¥"""
        
        # å¤„ç†å‚æ•°ï¼ˆå¯èƒ½æ˜¯åˆ—è¡¨ï¼‰
        if isinstance(blend_mode, list):
            blend_mode = blend_mode[0]
        if isinstance(feather_amount, list):
            feather_amount = feather_amount[0]
        if isinstance(paste_mode, list):
            paste_mode = paste_mode[0]
        if isinstance(target_index, list):
            target_index = target_index[0]
        if isinstance(color_match, list):
            color_match = color_match[0]
        
        # å¤„ç†åŸå§‹å›¾åƒ
        if isinstance(original_image, list):
            original_image = original_image[0]
        if len(original_image.shape) == 3:
            original_image = original_image.unsqueeze(0)
        
        # åˆ›å»ºè¾“å‡ºå›¾åƒçš„å‰¯æœ¬
        output_image = original_image.clone()
        batch_size, height, width, channels = output_image.shape
        
        # å¤„ç†ç²˜è´´å›¾åƒåˆ—è¡¨
        if not isinstance(paste_images, list):
            paste_images = [paste_images]
        
        # è§£æè¾¹ç•Œæ¡†
        bboxes_list = self.parse_bboxes(bboxes)
        
        num_paste_images = len(paste_images)
        num_bboxes = len(bboxes_list)
        
        #print(f"\nç²˜è´´å‚æ•°:")
        #print(f"- ç²˜è´´å›¾åƒæ•°é‡: {num_paste_images}")
        #print(f"- è¾¹ç•Œæ¡†æ•°é‡: {num_bboxes}")
        #print(f"- æ··åˆæ¨¡å¼: {blend_mode}")
        #print(f"- ç¾½åŒ–ç¨‹åº¦: {feather_amount}")
        #print(f"- é¢œè‰²åŒ¹é…: {color_match}")
        
        # åˆ›å»ºç´¯ç§¯é®ç½©
        cumulative_mask = torch.zeros((height, width), dtype=torch.float32, device=output_image.device)
        
        # æ ¹æ®æ¨¡å¼æ‰§è¡Œç²˜è´´
        if paste_mode == "æŒ‡å®šç´¢å¼•":
            if target_index < num_paste_images and target_index < num_bboxes:
                paste_img = paste_images[target_index]
                bbox = bboxes_list[target_index]
                
                output_image[0] = self.paste_single_image(
                    output_image[0], paste_img, bbox, blend_mode, feather_amount, color_match
                )
                
                # æ›´æ–°é®ç½©
                x1, y1, x2, y2 = [int(coord) for coord in bbox]
                x1, y1 = max(0, x1), max(0, y1)
                x2, y2 = min(width, x2), min(height, y2)
                if x2 > x1 and y2 > y1:
                    cumulative_mask[y1:y2, x1:x2] = 1.0
        
        elif paste_mode == "å¾ªç¯ä½¿ç”¨":
            for i in range(num_bboxes):
                paste_idx = i % num_paste_images
                paste_img = paste_images[paste_idx]
                bbox = bboxes_list[i]
                
                #print(f"\nç²˜è´´ç¬¬ {i+1}/{num_bboxes} ä¸ªåŒºåŸŸï¼ˆä½¿ç”¨å›¾åƒ {paste_idx+1}ï¼‰")
                
                output_image[0] = self.paste_single_image(
                    output_image[0], paste_img, bbox, blend_mode, feather_amount, color_match
                )
                
                # æ›´æ–°é®ç½©
                x1, y1, x2, y2 = [int(coord) for coord in bbox]
                x1, y1 = max(0, x1), max(0, y1)
                x2, y2 = min(width, x2), min(height, y2)
                if x2 > x1 and y2 > y1:
                    cumulative_mask[y1:y2, x1:x2] = 1.0
        
        else:  # å…¨éƒ¨ç²˜è´´
            max_items = min(num_paste_images, num_bboxes)
            
            for i in range(max_items):
                paste_img = paste_images[i]
                bbox = bboxes_list[i]
                
                #print(f"\nç²˜è´´ç¬¬ {i+1}/{max_items} ä¸ªå›¾åƒ")
                #print(f"è¾¹ç•Œæ¡†: {bbox}")
                
                output_image[0] = self.paste_single_image(
                    output_image[0], paste_img, bbox, blend_mode, feather_amount, color_match
                )
                
                # æ›´æ–°é®ç½©
                x1, y1, x2, y2 = [int(coord) for coord in bbox]
                x1, y1 = max(0, x1), max(0, y1)
                x2, y2 = min(width, x2), min(height, y2)
                if x2 > x1 and y2 > y1:
                    cumulative_mask[y1:y2, x1:x2] = 1.0
        
        # ç¡®ä¿è¾“å‡ºåœ¨0-1èŒƒå›´å†…
        output_image = torch.clamp(output_image, 0, 1)
        
        # æ·»åŠ æ‰¹æ¬¡ç»´åº¦åˆ°é®ç½©
        output_mask = cumulative_mask.unsqueeze(0)
        
        #print(f"\nç²˜è´´å®Œæˆ")
        #print(f"è¾“å‡ºå›¾åƒå°ºå¯¸: {output_image.shape}")
        #print(f"è¾“å‡ºé®ç½©å°ºå¯¸: {output_mask.shape}")
        
        return (output_image, output_mask)

# èŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "YoloImagePasteNode": YoloImagePasteNode
}

# èŠ‚ç‚¹æ˜¾ç¤ºåç§°æ˜ å°„
NODE_DISPLAY_NAME_MAPPINGS = {
    "YoloImagePasteNode": "ğŸ³YOLOå›¾åƒæ‹¼æ¥"
}