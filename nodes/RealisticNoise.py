import torch
import numpy as np
from PIL import Image
import random

class RealisticNoiseNode:
    """
    å°†AIç”Ÿæˆå›¾åƒçš„å™ªç‚¹è½¬æ¢ä¸ºæ›´çœŸå®çš„ç›¸æœºå™ªç‚¹
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),
                "å™ªç‚¹å¼ºåº¦": ("FLOAT", {
                    "default": 0.5,
                    "min": 0.0,
                    "max": 2.0,
                    "step": 0.1,
                    "display": "slider"
                }),
                "å…‰å­å™ªå£°": ("FLOAT", {
                    "default": 0.3,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.05,
                    "display": "slider"
                }),
                "çƒ­å™ªå£°": ("FLOAT", {
                    "default": 0.2,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.05,
                    "display": "slider"
                }),
                "è¯»å–å™ªå£°": ("FLOAT", {
                    "default": 0.1,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.05,
                    "display": "slider"
                }),
                "é¢œè‰²å™ªå£°": ("FLOAT", {
                    "default": 0.15,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.05,
                    "display": "slider"
                }),
                "ISOæ¨¡æ‹Ÿ": ("INT", {
                    "default": 800,
                    "min": 100,
                    "max": 12800,
                    "step": 100,
                    "display": "slider"
                }),
                "ä¿ç•™ç»†èŠ‚": ("FLOAT", {
                    "default": 0.7,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.05,
                    "display": "slider"
                }),
            },
            "optional": {
                "ç§å­": ("INT", {
                    "default": -1,
                    "min": -1,
                    "max": 2**32-1,
                })
            }
        }
    
    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("å›¾åƒ",)
    FUNCTION = "add_realistic_noise"
    CATEGORY = "ğŸ³Pond/image"
    
    def add_realistic_noise(self, image, å™ªç‚¹å¼ºåº¦, å…‰å­å™ªå£°, çƒ­å™ªå£°, è¯»å–å™ªå£°, é¢œè‰²å™ªå£°, ISOæ¨¡æ‹Ÿ, ä¿ç•™ç»†èŠ‚, ç§å­=-1):
        # è®¾ç½®éšæœºç§å­
        if ç§å­ != -1:
            torch.manual_seed(ç§å­)
            np.random.seed(ç§å­)
            random.seed(ç§å­)
        
        # è·å–å›¾åƒç»´åº¦
        batch_size, height, width, channels = image.shape
        device = image.device
        
        # å¤åˆ¶å›¾åƒä»¥é¿å…ä¿®æ”¹åŸå§‹æ•°æ®
        noisy_image = image.clone()
        
        # ISOå¢ç›Šæ¨¡æ‹Ÿ
        iso_factor = ISOæ¨¡æ‹Ÿ / 100.0
        overall_strength = å™ªç‚¹å¼ºåº¦ * iso_factor * 0.1
        
        # 1. æ·»åŠ å…‰å­å™ªå£°ï¼ˆShot Noiseï¼‰- æ³Šæ¾åˆ†å¸ƒ
        if å…‰å­å™ªå£° > 0:
            # æ¨¡æ‹Ÿå…‰å­å™ªå£°ï¼Œåœ¨æš—éƒ¨æ›´æ˜æ˜¾
            luminance = torch.mean(noisy_image, dim=3, keepdim=True)
            # æš—éƒ¨å™ªå£°æ›´å¼º
            dark_mask = 1.0 - luminance
            
            # ä½¿ç”¨æ³Šæ¾åˆ†å¸ƒçš„è¿‘ä¼¼ï¼ˆé«˜æ–¯ï¼‰
            photon_noise = torch.randn_like(noisy_image) * å…‰å­å™ªå£° * overall_strength
            photon_noise = photon_noise * dark_mask * 2.0
            noisy_image = noisy_image + photon_noise
        
        # 2. æ·»åŠ çƒ­å™ªå£°ï¼ˆThermal Noiseï¼‰- å›ºå®šæ¨¡å¼å™ªå£°
        if çƒ­å™ªå£° > 0:
            # åˆ›å»ºå›ºå®šæ¨¡å¼å™ªå£°
            thermal_pattern = torch.randn(1, height, width, 1, device=device) * çƒ­å™ªå£° * overall_strength * 0.5
            thermal_pattern = thermal_pattern.expand(batch_size, -1, -1, channels)
            
            # æ·»åŠ è½»å¾®çš„æ—¶é—´å˜åŒ–
            temporal_variation = torch.randn_like(noisy_image) * çƒ­å™ªå£° * overall_strength * 0.1
            thermal_noise = thermal_pattern + temporal_variation
            
            noisy_image = noisy_image + thermal_noise
        
        # 3. æ·»åŠ è¯»å–å™ªå£°ï¼ˆRead Noiseï¼‰- é«˜æ–¯åˆ†å¸ƒ
        if è¯»å–å™ªå£° > 0:
            read_noise = torch.randn_like(noisy_image) * è¯»å–å™ªå£° * overall_strength * 0.8
            noisy_image = noisy_image + read_noise
        
        # 4. æ·»åŠ é¢œè‰²å™ªå£°ï¼ˆColor Noiseï¼‰
        if é¢œè‰²å™ªå£° > 0:
            # ä¸ºæ¯ä¸ªé¢œè‰²é€šé“æ·»åŠ ä¸åŒå¼ºåº¦çš„å™ªå£°
            color_noise = torch.randn_like(noisy_image)
            # Ré€šé“å™ªå£°ç¨å¼º
            color_noise[:, :, :, 0] *= é¢œè‰²å™ªå£° * overall_strength * 1.2
            # Gé€šé“å™ªå£°æ ‡å‡†
            color_noise[:, :, :, 1] *= é¢œè‰²å™ªå£° * overall_strength * 1.0
            # Bé€šé“å™ªå£°æœ€å¼ºï¼ˆæ¨¡æ‹Ÿä¼ æ„Ÿå™¨ç‰¹æ€§ï¼‰
            color_noise[:, :, :, 2] *= é¢œè‰²å™ªå£° * overall_strength * 1.4
            
            noisy_image = noisy_image + color_noise
        
        # 5. æ¨¡æ‹Ÿä¼ æ„Ÿå™¨å“åº”éçº¿æ€§
        # åœ¨é«˜å…‰åŒºåŸŸå‡å°‘å™ªå£°ï¼ˆæ¨¡æ‹Ÿä¼ æ„Ÿå™¨é¥±å’Œï¼‰
        highlights = torch.clamp(luminance - 0.8, 0, 1) * 5.0
        noisy_image = torch.lerp(noisy_image, image, highlights)
        
        # 6. åº”ç”¨ç»†èŠ‚ä¿ç•™
        if ä¿ç•™ç»†èŠ‚ > 0:
            # ä½¿ç”¨è¾¹ç¼˜æ£€æµ‹ä¿ç•™ç»†èŠ‚
            # ç®€å•çš„è¾¹ç¼˜æ£€æµ‹
            dx = torch.abs(image[:, 1:, :, :] - image[:, :-1, :, :])
            dy = torch.abs(image[:, :, 1:, :] - image[:, :, :-1, :])
            
            # åˆ›å»ºè¾¹ç¼˜æ©ç 
            edge_mask = torch.zeros_like(image)
            edge_mask[:, 1:, :, :] += dx
            edge_mask[:, :-1, :, :] += dx
            edge_mask[:, :, 1:, :] += dy
            edge_mask[:, :, :-1, :] += dy
            
            edge_mask = torch.clamp(edge_mask * 5.0, 0, 1)
            
            # åœ¨è¾¹ç¼˜åŒºåŸŸæ··åˆåŸå§‹å›¾åƒä»¥ä¿ç•™ç»†èŠ‚
            noisy_image = torch.lerp(noisy_image, image, edge_mask * ä¿ç•™ç»†èŠ‚)
        
        # 7. æ·»åŠ è½»å¾®çš„æ¤’ç›å™ªå£°ï¼ˆSalt and Pepperï¼‰
        if random.random() < 0.3:  # 30%æ¦‚ç‡æ·»åŠ æ¤’ç›å™ªå£°
            salt_pepper_prob = 0.001 * overall_strength
            salt_mask = torch.rand_like(noisy_image[:, :, :, 0]) < salt_pepper_prob
            pepper_mask = torch.rand_like(noisy_image[:, :, :, 0]) < salt_pepper_prob
            
            salt_mask = salt_mask.unsqueeze(-1).expand(-1, -1, -1, channels)
            pepper_mask = pepper_mask.unsqueeze(-1).expand(-1, -1, -1, channels)
            
            noisy_image[salt_mask] = 1.0
            noisy_image[pepper_mask] = 0.0
        
        # 8. æœ€ç»ˆå¤„ç†
        # æ·»åŠ è½»å¾®çš„é«˜æ–¯æ¨¡ç³Šä»¥æ¨¡æ‹Ÿä¼ æ„Ÿå™¨çš„ä½é€šæ»¤æ³¢æ•ˆæœ
        if overall_strength > 0.5:
            # ç®€å•çš„3x3é«˜æ–¯æ¨¡ç³Š
            kernel = torch.tensor([[1, 2, 1], [2, 4, 2], [1, 2, 1]], dtype=torch.float32, device=device) / 16.0
            kernel = kernel.unsqueeze(0).unsqueeze(0)
            
            # å¯¹æ¯ä¸ªé€šé“åº”ç”¨æ¨¡ç³Š
            blurred = torch.zeros_like(noisy_image)
            for c in range(channels):
                channel = noisy_image[:, :, :, c:c+1].permute(0, 3, 1, 2)
                blurred_channel = torch.nn.functional.conv2d(channel, kernel, padding=1)
                blurred[:, :, :, c] = blurred_channel.permute(0, 2, 3, 1).squeeze(-1)
            
            # è½»å¾®æ··åˆæ¨¡ç³Šæ•ˆæœ
            blur_strength = min(0.3, overall_strength * 0.2)
            noisy_image = torch.lerp(noisy_image, blurred, blur_strength)
        
        # è£å‰ªåˆ°æœ‰æ•ˆèŒƒå›´
        noisy_image = torch.clamp(noisy_image, 0.0, 1.0)
        
        return (noisy_image,)
    
    @classmethod
    def IS_CHANGED(cls, **kwargs):
        # å¦‚æœç§å­æ˜¯-1ï¼ˆéšæœºï¼‰ï¼Œåˆ™æ¯æ¬¡éƒ½æ ‡è®°ä¸ºå·²æ›´æ”¹
        if kwargs.get('ç§å­', -1) == -1:
            return float("NaN")
        return None


# ç”¨äºæ³¨å†ŒèŠ‚ç‚¹
NODE_CLASS_MAPPINGS = {
    "RealisticNoiseNode": RealisticNoiseNode
}

# èŠ‚ç‚¹åœ¨UIä¸­æ˜¾ç¤ºçš„åç§°
NODE_DISPLAY_NAME_MAPPINGS = {
    "RealisticNoiseNode": "ğŸ³å™ªç‚¹è°ƒèŠ‚"
}