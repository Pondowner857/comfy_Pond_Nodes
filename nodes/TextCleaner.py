import re

class TextCleanerNode:
    def __init__(self):
        pass

    @classmethod
    def INPUT_TYPES(cls):
        """
        å®šä¹‰èŠ‚ç‚¹çš„è¾“å…¥ç±»å‹
        """
        return {
            "required": {
                "text": ("STRING", {"multiline": True, "dynamicPrompts": False}),
                "tags": ("STRING", {"multiline": True, "dynamicPrompts": False}),
                "mode": (["åˆ é™¤åŒ…å«æ ‡ç­¾/æç¤ºè¯çš„å¥å­", "åˆ é™¤æ ‡ç­¾/æç¤ºè¯"], {"default": "åˆ é™¤åŒ…å«æ ‡ç­¾/æç¤ºè¯çš„å¥å­"})
            }
        }

    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("cleaned_text",)
    FUNCTION = "clean_text"
    CATEGORY = "ğŸ³Pond/text"

    def parse_tags(self, tags):
        """
        è§£ææ ‡ç­¾ï¼Œæ”¯æŒå¤šç§åˆ†éš”æ–¹å¼ï¼ŒåŒ…æ‹¬ä¸­è‹±æ–‡æ ‡ç‚¹
        """
        # ä¸­è‹±æ–‡æ ‡ç‚¹ç¬¦å·é›†åˆ
        separators = r'[,;ã€\n\sã€‚ï¼Œï¼›ï¼šï¼Ÿï¼,.?!ï¼š]+' 
        
        # åˆ†å‰²å¹¶æ¸…ç†æ ‡ç­¾
        tag_list = [
            tag.strip().lower() 
            for tag in re.split(separators, tags) 
            if tag.strip()
        ]
        
        return tag_list

    def clean_text(self, text, tags, mode):
        """
        æ¸…ç†æ–‡æœ¬çš„ä¸»è¦å‡½æ•°
        
        :param text: è¾“å…¥æ–‡æœ¬
        :param tags: è¦åˆ é™¤çš„æ ‡ç­¾
        :param mode: æ¸…ç†æ¨¡å¼
        :return: æ¸…ç†åçš„æ–‡æœ¬
        """
        # å¦‚æœæ²¡æœ‰æ ‡ç­¾ï¼Œç›´æ¥è¿”å›åŸæ–‡
        if not tags:
            return (text,)

        # è§£ææ ‡ç­¾
        tag_list = self.parse_tags(tags)

        # å¤„ç†ä¸åŒçš„æ¸…ç†æ¨¡å¼
        if mode == "åˆ é™¤æ ‡ç­¾/æç¤ºè¯":
            # åˆ é™¤ç‰¹å®šæ ‡ç­¾/æç¤ºè¯
            for tag in tag_list:
                # ä½¿ç”¨æ­£åˆ™æ›¿æ¢ï¼Œå¿½ç•¥å¤§å°å†™
                text = re.sub(re.escape(tag), '', text, flags=re.IGNORECASE)
        
        elif mode == "åˆ é™¤åŒ…å«æ ‡ç­¾/æç¤ºè¯çš„å¥å­":
            # åˆ†å‰²å¥å­ï¼ˆæ”¯æŒä¸­æ–‡å’Œè‹±æ–‡çš„å¥å­åˆ†éš”ï¼‰
            sentences = re.split(r'([ã€‚ï¼ï¼Ÿ!?.]+)', text)
            
            # é‡æ–°ç»„è£…å¥å­ï¼Œæ’é™¤åŒ…å«æŒ‡å®šæ ‡ç­¾çš„å¥å­
            filtered_sentences = []
            for i in range(0, len(sentences), 2):
                # æ£€æŸ¥å¥å­æ˜¯å¦åŒ…å«ä»»ä½•æ ‡ç­¾
                if not any(tag in sentences[i].lower() for tag in tag_list):
                    # å¦‚æœå¥å­ä¸åŒ…å«æ ‡ç­¾ï¼ŒåŠ å…¥ç»“æœ
                    filtered_sentences.append(sentences[i])
                    # å¦‚æœæ˜¯æœ€åä¸€ä¸ªå¥å­å‰çš„åˆ†éš”ç¬¦ï¼Œä¹ŸåŠ å…¥
                    if i + 1 < len(sentences):
                        filtered_sentences.append(sentences[i+1])
            
            # é‡æ–°ç»„è£…æ–‡æœ¬
            text = ''.join(filtered_sentences)

        # è¿”å›æ¸…ç†åçš„æ–‡æœ¬
        return (text.strip(),)

# å®šä¹‰ WEB_DICT ä»¥æ”¯æŒèŠ‚ç‚¹åœ¨ ComfyUI ä¸­çš„å±•ç¤º
NODE_CLASS_MAPPINGS = {
    "TextCleanerNode": TextCleanerNode
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "TextCleanerNode": "ğŸ³æ–‡æœ¬æ¸…ç†å™¨"
}