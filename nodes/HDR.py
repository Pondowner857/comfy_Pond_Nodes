import torch
import numpy as np
from PIL import Image, ImageEnhance, ImageFilter, ImageOps, ImageDraw
import cv2
from scipy.ndimage import gaussian_filter
import colorsys

# é¢œè‰²åˆ†çº§èŠ‚ç‚¹
class ColorGradingNode:
    """
    ä¸“ä¸šé¢œè‰²åˆ†çº§èŠ‚ç‚¹ï¼Œæä¾›ç”µå½±çº§è°ƒè‰²åŠŸèƒ½
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),
                # é«˜å…‰ã€ä¸­é—´è°ƒã€é˜´å½±è°ƒæ•´
                "é«˜å…‰_çº¢": ("FLOAT", {"default": 0.0, "min": -1.0, "max": 1.0, "step": 0.01}),
                "é«˜å…‰_ç»¿": ("FLOAT", {"default": 0.0, "min": -1.0, "max": 1.0, "step": 0.01}),
                "é«˜å…‰_è“": ("FLOAT", {"default": 0.0, "min": -1.0, "max": 1.0, "step": 0.01}),
                "ä¸­é—´è°ƒ_çº¢": ("FLOAT", {"default": 0.0, "min": -1.0, "max": 1.0, "step": 0.01}),
                "ä¸­é—´è°ƒ_ç»¿": ("FLOAT", {"default": 0.0, "min": -1.0, "max": 1.0, "step": 0.01}),
                "ä¸­é—´è°ƒ_è“": ("FLOAT", {"default": 0.0, "min": -1.0, "max": 1.0, "step": 0.01}),
                "é˜´å½±_çº¢": ("FLOAT", {"default": 0.0, "min": -1.0, "max": 1.0, "step": 0.01}),
                "é˜´å½±_ç»¿": ("FLOAT", {"default": 0.0, "min": -1.0, "max": 1.0, "step": 0.01}),
                "é˜´å½±_è“": ("FLOAT", {"default": 0.0, "min": -1.0, "max": 1.0, "step": 0.01}),
                # è‰²å½©å¹³è¡¡
                "è‰²å½©å¹³è¡¡": ("FLOAT", {"default": 0.0, "min": -1.0, "max": 1.0, "step": 0.01}),
                "è‰²è°ƒåˆ†ç¦»å¼ºåº¦": ("FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01}),
            }
        }

    RETURN_TYPES = ("IMAGE",)
    FUNCTION = "apply_color_grading"
    CATEGORY = "ğŸ³Pond/é¢œè‰²"

    def apply_color_grading(self, image, é«˜å…‰_çº¢, é«˜å…‰_ç»¿, é«˜å…‰_è“,
                           ä¸­é—´è°ƒ_çº¢, ä¸­é—´è°ƒ_ç»¿, ä¸­é—´è°ƒ_è“,
                           é˜´å½±_çº¢, é˜´å½±_ç»¿, é˜´å½±_è“,
                           è‰²å½©å¹³è¡¡, è‰²è°ƒåˆ†ç¦»å¼ºåº¦):
        
        batch_size = image.shape[0]
        result_images = []
        
        for i in range(batch_size):
            img_array = image[i].cpu().numpy()
            img_array = (img_array * 255).astype(np.uint8)
            
            # åˆ›å»ºäº®åº¦è’™ç‰ˆ
            gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY).astype(np.float32) / 255.0
            
            # å®šä¹‰é«˜å…‰ã€ä¸­é—´è°ƒã€é˜´å½±åŒºåŸŸ
            highlights = np.power(gray, 2)
            shadows = 1 - np.power(1 - gray, 2)
            midtones = 1 - highlights - (1 - shadows)
            
            # æ‰©å±•è’™ç‰ˆåˆ°3é€šé“
            highlights = np.stack([highlights] * 3, axis=2)
            midtones = np.stack([midtones] * 3, axis=2)
            shadows = np.stack([shadows] * 3, axis=2)
            
            # åº”ç”¨é¢œè‰²åˆ†çº§
            result = img_array.astype(np.float32) / 255.0
            
            # é«˜å…‰è°ƒæ•´
            result[:, :, 0] += highlights[:, :, 0] * é«˜å…‰_çº¢
            result[:, :, 1] += highlights[:, :, 1] * é«˜å…‰_ç»¿
            result[:, :, 2] += highlights[:, :, 2] * é«˜å…‰_è“
            
            # ä¸­é—´è°ƒè°ƒæ•´
            result[:, :, 0] += midtones[:, :, 0] * ä¸­é—´è°ƒ_çº¢
            result[:, :, 1] += midtones[:, :, 1] * ä¸­é—´è°ƒ_ç»¿
            result[:, :, 2] += midtones[:, :, 2] * ä¸­é—´è°ƒ_è“
            
            # é˜´å½±è°ƒæ•´
            result[:, :, 0] += shadows[:, :, 0] * é˜´å½±_çº¢
            result[:, :, 1] += shadows[:, :, 1] * é˜´å½±_ç»¿
            result[:, :, 2] += shadows[:, :, 2] * é˜´å½±_è“
            
            # è‰²å½©å¹³è¡¡
            if è‰²å½©å¹³è¡¡ != 0:
                result = self.apply_color_balance(result, è‰²å½©å¹³è¡¡)
            
            # è‰²è°ƒåˆ†ç¦»
            if è‰²è°ƒåˆ†ç¦»å¼ºåº¦ > 0:
                result = self.apply_split_toning(result, è‰²è°ƒåˆ†ç¦»å¼ºåº¦)
            
            # é™åˆ¶èŒƒå›´å¹¶è½¬æ¢
            result = np.clip(result, 0, 1)
            result_images.append(result)
        
        result_tensor = torch.from_numpy(np.stack(result_images))
        return (result_tensor,)
    
    def apply_color_balance(self, image, balance):
        """åº”ç”¨è‰²å½©å¹³è¡¡"""
        # è°ƒæ•´çº¢-é’å’Œé»„-è“å¹³è¡¡
        image[:, :, 0] *= (1 + balance * 0.1)  # çº¢
        image[:, :, 2] *= (1 - balance * 0.1)  # è“
        return image
    
    def apply_split_toning(self, image, strength):
        """åº”ç”¨è‰²è°ƒåˆ†ç¦»æ•ˆæœ"""
        # ä¸ºé«˜å…‰æ·»åŠ æš–è‰²è°ƒï¼Œé˜´å½±æ·»åŠ å†·è‰²è°ƒ
        gray = np.mean(image, axis=2)
        
        # é«˜å…‰æš–è‰²
        highlight_mask = (gray > 0.5).astype(np.float32) * strength
        image[:, :, 0] += highlight_mask * 0.1
        image[:, :, 1] += highlight_mask * 0.05
        
        # é˜´å½±å†·è‰²
        shadow_mask = (gray < 0.5).astype(np.float32) * strength
        image[:, :, 2] += shadow_mask * 0.1
        
        return image


# HDRæ•ˆæœèŠ‚ç‚¹
class HDREffectNode:
    """
    HDRæ•ˆæœå¤„ç†èŠ‚ç‚¹ï¼Œå¢å¼ºå›¾åƒåŠ¨æ€èŒƒå›´
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),
                "HDRå¼ºåº¦": ("FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}),
                "è‰²è°ƒæ˜ å°„": (["Reinhard", "Drago", "Mantiuk", "çº¿æ€§"],),
                "ç»†èŠ‚å¢å¼º": ("FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}),
                "å±€éƒ¨å¯¹æ¯”åº¦": ("FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}),
                "é«˜å…‰å‹ç¼©": ("FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01}),
                "é˜´å½±æå‡": ("FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01}),
            }
        }

    RETURN_TYPES = ("IMAGE",)
    FUNCTION = "apply_hdr_effect"
    CATEGORY = "ğŸ³Pond/é¢œè‰²"

    def apply_hdr_effect(self, image, HDRå¼ºåº¦, è‰²è°ƒæ˜ å°„, ç»†èŠ‚å¢å¼º, 
                        å±€éƒ¨å¯¹æ¯”åº¦, é«˜å…‰å‹ç¼©, é˜´å½±æå‡):
        
        batch_size = image.shape[0]
        result_images = []
        
        for i in range(batch_size):
            img_array = image[i].cpu().numpy()
            
            # åº”ç”¨HDRå¤„ç†
            hdr_result = self.process_hdr(img_array, HDRå¼ºåº¦, è‰²è°ƒæ˜ å°„)
            
            # ç»†èŠ‚å¢å¼º
            if ç»†èŠ‚å¢å¼º > 0:
                hdr_result = self.enhance_details(hdr_result, ç»†èŠ‚å¢å¼º)
            
            # å±€éƒ¨å¯¹æ¯”åº¦è°ƒæ•´
            if å±€éƒ¨å¯¹æ¯”åº¦ > 0:
                hdr_result = self.enhance_local_contrast(hdr_result, å±€éƒ¨å¯¹æ¯”åº¦)
            
            # é«˜å…‰å’Œé˜´å½±è°ƒæ•´
            hdr_result = self.adjust_highlights_shadows(hdr_result, é«˜å…‰å‹ç¼©, é˜´å½±æå‡)
            
            result_images.append(hdr_result)
        
        result_tensor = torch.from_numpy(np.stack(result_images))
        return (result_tensor,)
    
    def process_hdr(self, image, strength, tone_mapping):
        """HDRå¤„ç†"""
        # è½¬æ¢åˆ°float32
        img_float = image.astype(np.float32)
        
        # è®¡ç®—äº®åº¦
        luminance = 0.299 * img_float[:, :, 0] + 0.587 * img_float[:, :, 1] + 0.114 * img_float[:, :, 2]
        
        # åº”ç”¨ä¸åŒçš„è‰²è°ƒæ˜ å°„ç®—æ³•
        if tone_mapping == "Reinhard":
            # Reinhardè‰²è°ƒæ˜ å°„
            mapped_lum = luminance / (1.0 + luminance)
        elif tone_mapping == "Drago":
            # Dragoå¯¹æ•°æ˜ å°„
            bias = 0.85
            mapped_lum = np.log10(1 + luminance) / np.log10(1 + np.max(luminance))
            mapped_lum = np.power(mapped_lum, np.log(bias) / np.log(0.5))
        elif tone_mapping == "Mantiuk":
            # ç®€åŒ–çš„Mantiukæ˜ å°„
            mapped_lum = luminance / (luminance + 1)
            mapped_lum = np.power(mapped_lum, 1.0 / 2.2)
        else:  # çº¿æ€§
            mapped_lum = np.clip(luminance, 0, 1)
        
        # è®¡ç®—ç¼©æ”¾å› å­
        scale = np.where(luminance > 0, mapped_lum / luminance, 1)
        scale = scale[:, :, np.newaxis]
        
        # åº”ç”¨æ˜ å°„
        result = img_float * scale
        
        # æ··åˆåŸå›¾å’ŒHDRç»“æœ
        result = img_float * (1 - strength) + result * strength
        
        return np.clip(result, 0, 1)
    
    def enhance_details(self, image, strength):
        """å¢å¼ºç»†èŠ‚"""
        # ä½¿ç”¨éé”åŒ–æ©æ¨¡å¢å¼ºç»†èŠ‚
        img_uint8 = (image * 255).astype(np.uint8)
        blurred = cv2.GaussianBlur(img_uint8, (0, 0), 3)
        
        # è®¡ç®—ç»†èŠ‚å±‚
        details = img_uint8.astype(np.float32) - blurred.astype(np.float32)
        
        # å¢å¼ºç»†èŠ‚
        enhanced = img_uint8.astype(np.float32) + details * strength * 2
        
        return np.clip(enhanced / 255.0, 0, 1)
    
    def enhance_local_contrast(self, image, strength):
        """å¢å¼ºå±€éƒ¨å¯¹æ¯”åº¦"""
        # CLAHE (Contrast Limited Adaptive Histogram Equalization)
        img_lab = cv2.cvtColor((image * 255).astype(np.uint8), cv2.COLOR_RGB2LAB)
        
        # åˆ›å»ºCLAHEå¯¹è±¡
        clahe = cv2.createCLAHE(clipLimit=2.0 * strength + 1.0, tileGridSize=(8, 8))
        
        # åªå¯¹Lé€šé“åº”ç”¨
        img_lab[:, :, 0] = clahe.apply(img_lab[:, :, 0])
        
        # è½¬æ¢å›RGB
        result = cv2.cvtColor(img_lab, cv2.COLOR_LAB2RGB)
        
        return result.astype(np.float32) / 255.0
    
    def adjust_highlights_shadows(self, image, highlight_compression, shadow_lift):
        """è°ƒæ•´é«˜å…‰å’Œé˜´å½±"""
        # è®¡ç®—äº®åº¦
        luminance = np.mean(image, axis=2)
        
        # é«˜å…‰å‹ç¼©
        if highlight_compression > 0:
            highlight_mask = np.clip((luminance - 0.7) / 0.3, 0, 1)
            compression = 1 - highlight_mask * highlight_compression * 0.5
            image = image * compression[:, :, np.newaxis]
        
        # é˜´å½±æå‡
        if shadow_lift > 0:
            shadow_mask = np.clip((0.3 - luminance) / 0.3, 0, 1)
            lift = 1 + shadow_mask * shadow_lift * 0.5
            image = image * lift[:, :, np.newaxis]
        
        return np.clip(image, 0, 1)


# çš®è‚¤ç¾åŒ–èŠ‚ç‚¹
class SkinEnhancementNode:
    """
    æ™ºèƒ½çš®è‚¤ç¾åŒ–èŠ‚ç‚¹ï¼Œä¸“é—¨ç”¨äºäººåƒåæœŸå¤„ç†
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),
                "ç£¨çš®å¼ºåº¦": ("FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}),
                "ç¾ç™½ç¨‹åº¦": ("FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01}),
                "çº¢æ¶¦åº¦": ("FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01}),
                "ç»†èŠ‚ä¿ç•™": ("FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}),
                "å»ç‘•ç–µ": ("BOOLEAN", {"default": True}),
                "çœ¼ç›å¢å¼º": ("FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01}),
                "ç‰™é½¿ç¾ç™½": ("FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01}),
            }
        }

    RETURN_TYPES = ("IMAGE",)
    FUNCTION = "enhance_skin"
    CATEGORY = "ğŸ³Pond/é¢œè‰²"

    def enhance_skin(self, image, ç£¨çš®å¼ºåº¦, ç¾ç™½ç¨‹åº¦, çº¢æ¶¦åº¦, 
                    ç»†èŠ‚ä¿ç•™, å»ç‘•ç–µ, çœ¼ç›å¢å¼º, ç‰™é½¿ç¾ç™½):
        
        batch_size = image.shape[0]
        result_images = []
        
        for i in range(batch_size):
            img_array = image[i].cpu().numpy()
            img_uint8 = (img_array * 255).astype(np.uint8)
            
            # æ£€æµ‹çš®è‚¤åŒºåŸŸ
            skin_mask = self.detect_skin(img_uint8)
            
            # ç£¨çš®å¤„ç†
            if ç£¨çš®å¼ºåº¦ > 0:
                img_uint8 = self.smooth_skin(img_uint8, skin_mask, ç£¨çš®å¼ºåº¦, ç»†èŠ‚ä¿ç•™)
            
            # ç¾ç™½å¤„ç†
            if ç¾ç™½ç¨‹åº¦ > 0:
                img_uint8 = self.whiten_skin(img_uint8, skin_mask, ç¾ç™½ç¨‹åº¦)
            
            # å¢åŠ çº¢æ¶¦åº¦
            if çº¢æ¶¦åº¦ > 0:
                img_uint8 = self.add_blush(img_uint8, skin_mask, çº¢æ¶¦åº¦)
            
            # å»ç‘•ç–µ
            if å»ç‘•ç–µ:
                img_uint8 = self.remove_blemishes(img_uint8, skin_mask)
            
            # çœ¼ç›å¢å¼º
            if çœ¼ç›å¢å¼º > 0:
                img_uint8 = self.enhance_eyes(img_uint8, çœ¼ç›å¢å¼º)
            
            # ç‰™é½¿ç¾ç™½
            if ç‰™é½¿ç¾ç™½ > 0:
                img_uint8 = self.whiten_teeth(img_uint8, ç‰™é½¿ç¾ç™½)
            
            result_images.append(img_uint8.astype(np.float32) / 255.0)
        
        result_tensor = torch.from_numpy(np.stack(result_images))
        return (result_tensor,)
    
    def detect_skin(self, image):
        """æ£€æµ‹çš®è‚¤åŒºåŸŸ"""
        # è½¬æ¢åˆ°YCrCbè‰²å½©ç©ºé—´
        ycrcb = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)
        
        # å®šä¹‰çš®è‚¤è‰²å½©èŒƒå›´
        lower = np.array([0, 133, 77], dtype=np.uint8)
        upper = np.array([255, 173, 127], dtype=np.uint8)
        
        # åˆ›å»ºçš®è‚¤æ©æ¨¡
        skin_mask = cv2.inRange(ycrcb, lower, upper)
        
        # å½¢æ€å­¦æ“ä½œä¼˜åŒ–æ©æ¨¡
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11))
        skin_mask = cv2.erode(skin_mask, kernel, iterations=1)
        skin_mask = cv2.dilate(skin_mask, kernel, iterations=2)
        skin_mask = cv2.GaussianBlur(skin_mask, (5, 5), 0)
        
        return skin_mask.astype(np.float32) / 255.0
    
    def smooth_skin(self, image, skin_mask, strength, detail_preserve):
        """ç£¨çš®å¤„ç†"""
        # ä½¿ç”¨åŒè¾¹æ»¤æ³¢ä¿æŒè¾¹ç¼˜
        smooth = cv2.bilateralFilter(image, 
                                    int(15 * strength), 
                                    int(80 * strength), 
                                    int(80 * strength))
        
        # ä¿ç•™ç»†èŠ‚
        if detail_preserve > 0:
            # é«˜é€šæ»¤æ³¢æå–ç»†èŠ‚
            blur = cv2.GaussianBlur(image, (21, 21), 0)
            detail = image.astype(np.float32) - blur.astype(np.float32)
            
            # æ·»åŠ å›éƒ¨åˆ†ç»†èŠ‚
            smooth = smooth.astype(np.float32) + detail * detail_preserve
            smooth = np.clip(smooth, 0, 255).astype(np.uint8)
        
        # åº”ç”¨è’™ç‰ˆ
        skin_mask_3ch = np.stack([skin_mask] * 3, axis=2)
        result = image * (1 - skin_mask_3ch) + smooth * skin_mask_3ch
        
        return result.astype(np.uint8)
    
    def whiten_skin(self, image, skin_mask, strength):
        """ç¾ç™½çš®è‚¤"""
        # è½¬æ¢åˆ°HSV
        hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV).astype(np.float32)
        
        # å¢åŠ æ˜åº¦ï¼Œé™ä½é¥±å’Œåº¦
        skin_mask_expand = skin_mask[:, :, np.newaxis]
        hsv[:, :, 2] += skin_mask_expand[:, :, 0] * 30 * strength  # æ˜åº¦
        hsv[:, :, 1] *= 1 - (skin_mask_expand[:, :, 0] * 0.3 * strength)  # é¥±å’Œåº¦
        
        # é™åˆ¶èŒƒå›´
        hsv[:, :, 1] = np.clip(hsv[:, :, 1], 0, 255)
        hsv[:, :, 2] = np.clip(hsv[:, :, 2], 0, 255)
        
        # è½¬æ¢å›RGB
        result = cv2.cvtColor(hsv.astype(np.uint8), cv2.COLOR_HSV2RGB)
        
        return result
    
    def add_blush(self, image, skin_mask, strength):
        """å¢åŠ çº¢æ¶¦åº¦"""
        # åœ¨è„¸é¢ŠåŒºåŸŸå¢åŠ çº¢è‰²
        result = image.copy()
        skin_mask_3ch = np.stack([skin_mask] * 3, axis=2)
        
        # å¢åŠ çº¢è‰²é€šé“
        blush = image.astype(np.float32)
        blush[:, :, 0] += 20 * strength  # çº¢è‰²
        blush[:, :, 1] += 10 * strength  # ç•¥å¾®å¢åŠ ç»¿è‰²
        
        # åº”ç”¨è’™ç‰ˆ
        result = image * (1 - skin_mask_3ch * strength * 0.5) + blush * skin_mask_3ch * strength * 0.5
        
        return np.clip(result, 0, 255).astype(np.uint8)
    
    def remove_blemishes(self, image, skin_mask):
        """å»é™¤ç‘•ç–µ"""
        # ä½¿ç”¨ä¸­å€¼æ»¤æ³¢å»é™¤å°ç‘•ç–µ
        result = image.copy()
        
        # åªåœ¨çš®è‚¤åŒºåŸŸåº”ç”¨
        skin_area = cv2.medianBlur(image, 5)
        
        skin_mask_3ch = np.stack([skin_mask] * 3, axis=2)
        result = image * (1 - skin_mask_3ch * 0.3) + skin_area * skin_mask_3ch * 0.3
        
        return result.astype(np.uint8)
    
    def enhance_eyes(self, image, strength):
        """å¢å¼ºçœ¼ç›"""
        # ç®€åŒ–å¤„ç†ï¼šå¢åŠ å¯¹æ¯”åº¦å’Œé”åº¦
        # å®é™…åº”ç”¨ä¸­éœ€è¦çœ¼ç›æ£€æµ‹
        result = image.copy()
        
        # å¢åŠ å±€éƒ¨å¯¹æ¯”åº¦å’Œé”åº¦
        kernel = np.array([[-1, -1, -1],
                          [-1, 9, -1],
                          [-1, -1, -1]]) * strength * 0.1
        
        sharpened = cv2.filter2D(image, -1, kernel)
        result = cv2.addWeighted(image, 1 - strength * 0.3, sharpened, strength * 0.3, 0)
        
        return np.clip(result, 0, 255).astype(np.uint8)
    
    def whiten_teeth(self, image, strength):
        """ç¾ç™½ç‰™é½¿"""
        # ç®€åŒ–å¤„ç†ï¼šæ£€æµ‹ç™½è‰²åŒºåŸŸå¹¶å¢å¼º
        # å®é™…åº”ç”¨ä¸­éœ€è¦ç‰™é½¿æ£€æµ‹
        result = image.copy()
        
        # æ£€æµ‹æ¥è¿‘ç™½è‰²çš„åŒºåŸŸ
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        _, white_mask = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)
        
        # è½»å¾®å¢åŠ äº®åº¦
        white_area = image.astype(np.float32)
        white_area += 20 * strength
        
        # åº”ç”¨è’™ç‰ˆ
        white_mask_3ch = np.stack([white_mask] * 3, axis=2).astype(np.float32) / 255.0
        result = image * (1 - white_mask_3ch * strength * 0.5) + white_area * white_mask_3ch * strength * 0.5
        
        return np.clip(result, 0, 255).astype(np.uint8)


# è‰ºæœ¯æ•ˆæœèŠ‚ç‚¹
class ArtisticEffectsNode:
    """
    è‰ºæœ¯æ•ˆæœèŠ‚ç‚¹ï¼Œæä¾›å„ç§è‰ºæœ¯é£æ ¼åŒ–æ•ˆæœ
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),
                "æ•ˆæœç±»å‹": (["æ²¹ç”»", "æ°´å½©", "ç´ æ", "æ¼«ç”»", "å°è±¡æ´¾", "ç‚¹å½©ç”»", "ç‰ˆç”»", "é©¬èµ›å…‹"],),
                "æ•ˆæœå¼ºåº¦": ("FLOAT", {"default": 0.7, "min": 0.0, "max": 1.0, "step": 0.01}),
                "ç¬”è§¦å¤§å°": ("INT", {"default": 5, "min": 1, "max": 20, "step": 1}),
                "è‰²å½©ç®€åŒ–": ("INT", {"default": 0, "min": 0, "max": 32, "step": 1}),
                "çº¹ç†å¼ºåº¦": ("FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}),
                "ä¿ç•™ç»†èŠ‚": ("FLOAT", {"default": 0.3, "min": 0.0, "max": 1.0, "step": 0.01}),
            }
        }

    RETURN_TYPES = ("IMAGE",)
    FUNCTION = "apply_artistic_effect"
    CATEGORY = "ğŸ³Pond/é¢œè‰²"

    def apply_artistic_effect(self, image, æ•ˆæœç±»å‹, æ•ˆæœå¼ºåº¦, ç¬”è§¦å¤§å°, 
                            è‰²å½©ç®€åŒ–, çº¹ç†å¼ºåº¦, ä¿ç•™ç»†èŠ‚):
        
        batch_size = image.shape[0]
        result_images = []
        
        for i in range(batch_size):
            img_array = image[i].cpu().numpy()
            img_uint8 = (img_array * 255).astype(np.uint8)
            
            if æ•ˆæœç±»å‹ == "æ²¹ç”»":
                result = self.oil_painting_effect(img_uint8, ç¬”è§¦å¤§å°, æ•ˆæœå¼ºåº¦)
            elif æ•ˆæœç±»å‹ == "æ°´å½©":
                result = self.watercolor_effect(img_uint8, æ•ˆæœå¼ºåº¦, çº¹ç†å¼ºåº¦)
            elif æ•ˆæœç±»å‹ == "ç´ æ":
                result = self.pencil_sketch_effect(img_uint8, æ•ˆæœå¼ºåº¦, ä¿ç•™ç»†èŠ‚)
            elif æ•ˆæœç±»å‹ == "æ¼«ç”»":
                result = self.cartoon_effect(img_uint8, è‰²å½©ç®€åŒ–, æ•ˆæœå¼ºåº¦)
            elif æ•ˆæœç±»å‹ == "å°è±¡æ´¾":
                result = self.impressionist_effect(img_uint8, ç¬”è§¦å¤§å°, æ•ˆæœå¼ºåº¦)
            elif æ•ˆæœç±»å‹ == "ç‚¹å½©ç”»":
                result = self.pointillism_effect(img_uint8, ç¬”è§¦å¤§å°, æ•ˆæœå¼ºåº¦)
            elif æ•ˆæœç±»å‹ == "ç‰ˆç”»":
                result = self.engraving_effect(img_uint8, æ•ˆæœå¼ºåº¦)
            elif æ•ˆæœç±»å‹ == "é©¬èµ›å…‹":
                result = self.mosaic_effect(img_uint8, ç¬”è§¦å¤§å°, æ•ˆæœå¼ºåº¦)
            else:
                result = img_uint8
            
            result_images.append(result.astype(np.float32) / 255.0)
        
        result_tensor = torch.from_numpy(np.stack(result_images))
        return (result_tensor,)
    
    def oil_painting_effect(self, image, brush_size, strength):
        """æ²¹ç”»æ•ˆæœ - ä¸ä¾èµ–xphotoæ¨¡å—çš„å®ç°"""
        h, w = image.shape[:2]
        
        # 1. ä½¿ç”¨è¾¹ç¼˜ä¿ç•™æ»¤æ³¢æ¨¡æ‹Ÿæ²¹ç”»çš„å¹³æ»‘æ•ˆæœ
        # å¤šæ¬¡åº”ç”¨åŒè¾¹æ»¤æ³¢ä»¥å¢å¼ºæ•ˆæœ
        result = image.copy()
        for _ in range(3):
            result = cv2.bilateralFilter(result, brush_size * 2, 50, 50)
        
        # 2. é¢œè‰²é‡åŒ–ï¼Œæ¨¡æ‹Ÿæ²¹ç”»çš„è‰²å—æ•ˆæœ
        # å‡å°‘é¢œè‰²æ•°é‡
        div = 32  # é¢œè‰²çº§åˆ«
        result = result // div * div + div // 2
        
        # 3. åˆ›å»ºæ²¹ç”»ç¬”è§¦çº¹ç†
        # ä½¿ç”¨å½¢æ€å­¦æ“ä½œåˆ›å»ºç¬”è§¦æ•ˆæœ
        kernel_size = max(3, brush_size)
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))
        
        # å¯¹æ¯ä¸ªé€šé“åˆ†åˆ«å¤„ç†
        for i in range(3):
            result[:, :, i] = cv2.morphologyEx(result[:, :, i], cv2.MORPH_CLOSE, kernel)
        
        # 4. æ·»åŠ è½»å¾®çš„çº¹ç†å¢å¼º
        # ä½¿ç”¨æ‹‰æ™®æ‹‰æ–¯ç®—å­æ£€æµ‹è¾¹ç¼˜
        gray = cv2.cvtColor(result, cv2.COLOR_RGB2GRAY)
        edges = cv2.Laplacian(gray, cv2.CV_64F)
        edges = np.absolute(edges)
        edges = np.uint8(np.clip(edges, 0, 255))
        
        # å°†è¾¹ç¼˜æ·»åŠ å›å›¾åƒä»¥å¢å¼ºçº¹ç†
        edges_3ch = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)
        result = cv2.addWeighted(result, 1.0, edges_3ch, 0.1, 0)
        
        # 5. æœ€ç»ˆæ··åˆ
        result = cv2.addWeighted(image, 1 - strength, result, strength, 0)
        
        return result
    
    def watercolor_effect(self, image, strength, texture_strength):
        """æ°´å½©æ•ˆæœ"""
        # è¾¹ç¼˜ä¿ç•™æ»¤æ³¢
        result = cv2.bilateralFilter(image, 15, 80, 80)
        result = cv2.bilateralFilter(result, 15, 80, 80)
        
        # åˆ›å»ºæ°´å½©çº¹ç†
        # ä½¿ç”¨éšæœºå™ªå£°æ¨¡æ‹Ÿæ°´å½©æ™•æŸ“
        h, w = image.shape[:2]
        texture = np.random.normal(0, 25 * texture_strength, (h, w, 3))
        
        # åº”ç”¨çº¹ç†
        result = result.astype(np.float32) + texture
        result = np.clip(result, 0, 255).astype(np.uint8)
        
        # é¢œè‰²ç®€åŒ–
        result = cv2.edgePreservingFilter(result, flags=1, sigma_s=60, sigma_r=0.4)
        
        # æ··åˆ
        result = cv2.addWeighted(image, 1 - strength, result, strength, 0)
        
        return result
    
    def pencil_sketch_effect(self, image, strength, detail_preserve):
        """ç´ ææ•ˆæœ"""
        # è½¬æ¢ä¸ºç°åº¦
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        
        # åè½¬
        inv_gray = 255 - gray
        
        # é«˜æ–¯æ¨¡ç³Š
        blur = cv2.GaussianBlur(inv_gray, (21, 21), 0)
        
        # é¢œè‰²å‡æ·¡æ··åˆ
        sketch = cv2.divide(gray, 255 - blur, scale=256)
        
        # ä¿ç•™éƒ¨åˆ†ç»†èŠ‚
        if detail_preserve > 0:
            edges = cv2.Canny(gray, 50, 150)
            sketch = cv2.addWeighted(sketch, 1 - detail_preserve, edges, detail_preserve, 0)
        
        # è½¬æ¢å›ä¸‰é€šé“
        sketch_3ch = cv2.cvtColor(sketch, cv2.COLOR_GRAY2RGB)
        
        # æ··åˆ
        result = cv2.addWeighted(image, 1 - strength, sketch_3ch, strength, 0)
        
        return result
    
    def cartoon_effect(self, image, num_colors, strength):
        """æ¼«ç”»æ•ˆæœ"""
        # è¾¹ç¼˜ä¿ç•™æ»¤æ³¢
        smooth = cv2.bilateralFilter(image, 15, 80, 80)
        smooth = cv2.bilateralFilter(smooth, 15, 80, 80)
        
        # è¾¹ç¼˜æ£€æµ‹
        gray = cv2.cvtColor(smooth, cv2.COLOR_RGB2GRAY)
        edges = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, 
                                     cv2.THRESH_BINARY, 9, 10)
        
        # é¢œè‰²é‡åŒ–
        if num_colors > 0:
            # K-meansé¢œè‰²èšç±»
            data = smooth.reshape((-1, 3))
            data = np.float32(data)
            
            criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 20, 1.0)
            _, labels, centers = cv2.kmeans(data, num_colors, None, criteria, 10, 
                                           cv2.KMEANS_RANDOM_CENTERS)
            
            centers = np.uint8(centers)
            quantized = centers[labels.flatten()]
            quantized = quantized.reshape(smooth.shape)
        else:
            quantized = smooth
        
        # å°†è¾¹ç¼˜è½¬æ¢ä¸ºä¸‰é€šé“
        edges = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)
        edges = cv2.bitwise_not(edges)
        
        # åˆå¹¶è¾¹ç¼˜å’Œé¢œè‰²
        cartoon = cv2.bitwise_and(quantized, edges)
        
        # æ··åˆ
        result = cv2.addWeighted(image, 1 - strength, cartoon, strength, 0)
        
        return result
    
    def impressionist_effect(self, image, brush_size, strength):
        """å°è±¡æ´¾æ•ˆæœ"""
        h, w = image.shape[:2]
        result = np.zeros_like(image)
        
        # åˆ›å»ºéšæœºç¬”è§¦
        num_strokes = 1000
        for _ in range(num_strokes):
            # éšæœºä½ç½®
            x = np.random.randint(0, w)
            y = np.random.randint(0, h)
            
            # è·å–è¯¥ç‚¹çš„é¢œè‰²
            color = image[y, x]
            
            # éšæœºç¬”è§¦å¤§å°å’Œè§’åº¦
            size = np.random.randint(brush_size, brush_size * 2)
            angle = np.random.randint(0, 360)
            
            # ç»˜åˆ¶æ¤­åœ†ç¬”è§¦
            axes = (size, size // 2)
            cv2.ellipse(result, (x, y), axes, angle, 0, 360, color.tolist(), -1)
        
        # æ··åˆ
        result = cv2.addWeighted(image, 1 - strength, result, strength, 0)
        
        return result
    
    def pointillism_effect(self, image, dot_size, strength):
        """ç‚¹å½©ç”»æ•ˆæœ"""
        h, w = image.shape[:2]
        result = np.ones_like(image) * 255  # ç™½è‰²èƒŒæ™¯
        
        # åˆ›å»ºç‚¹é˜µ
        step = dot_size * 2
        for y in range(0, h, step):
            for x in range(0, w, step):
                # è·å–åŒºåŸŸå¹³å‡é¢œè‰²
                roi = image[y:y+step, x:x+step]
                if roi.size > 0:
                    color = np.mean(roi, axis=(0, 1))
                    
                    # ç»˜åˆ¶åœ†ç‚¹
                    cv2.circle(result, (x + step//2, y + step//2), 
                             dot_size, color.tolist(), -1)
        
        # æ··åˆ
        result = cv2.addWeighted(image, 1 - strength, result, strength, 0)
        
        return result
    
    def engraving_effect(self, image, strength):
        """ç‰ˆç”»æ•ˆæœ"""
        # è½¬æ¢ä¸ºç°åº¦
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        
        # åˆ›å»ºçº¿æ¡çº¹ç†
        h, w = gray.shape
        texture = np.zeros_like(gray)
        
        # æ°´å¹³çº¿æ¡
        for y in range(0, h, 2):
            texture[y, :] = 255
        
        # æ ¹æ®äº®åº¦è°ƒåˆ¶çº¿æ¡
        result = np.where(gray > 128, texture, 255 - texture)
        
        # è½¬æ¢å›ä¸‰é€šé“
        result = cv2.cvtColor(result, cv2.COLOR_GRAY2RGB)
        
        # æ··åˆ
        result = cv2.addWeighted(image, 1 - strength, result, strength, 0)
        
        return result
    
    def mosaic_effect(self, image, block_size, strength):
        """é©¬èµ›å…‹æ•ˆæœ"""
        h, w = image.shape[:2]
        result = image.copy()
        
        # åˆ›å»ºé©¬èµ›å…‹
        for y in range(0, h, block_size):
            for x in range(0, w, block_size):
                # è·å–å—çš„å¹³å‡é¢œè‰²
                roi = image[y:y+block_size, x:x+block_size]
                if roi.size > 0:
                    color = np.mean(roi, axis=(0, 1))
                    result[y:y+block_size, x:x+block_size] = color
        
        # æ··åˆ
        result = cv2.addWeighted(image, 1 - strength, result, strength, 0)
        
        return result


# é€‰æ‹©æ€§é¢œè‰²è°ƒæ•´èŠ‚ç‚¹
class SelectiveColorNode:
    """
    é€‰æ‹©æ€§é¢œè‰²è°ƒæ•´èŠ‚ç‚¹ï¼Œå¯ä»¥é’ˆå¯¹ç‰¹å®šé¢œè‰²èŒƒå›´è¿›è¡Œè°ƒæ•´
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),
                "ç›®æ ‡é¢œè‰²": (["çº¢è‰²", "é»„è‰²", "ç»¿è‰²", "é’è‰²", "è“è‰²", "å“çº¢", "ç™½è‰²", "é»‘è‰²"],),
                "è‰²ç›¸åç§»": ("FLOAT", {"default": 0.0, "min": -180.0, "max": 180.0, "step": 1.0}),
                "é¥±å’Œåº¦è°ƒæ•´": ("FLOAT", {"default": 0.0, "min": -1.0, "max": 1.0, "step": 0.01}),
                "æ˜åº¦è°ƒæ•´": ("FLOAT", {"default": 0.0, "min": -1.0, "max": 1.0, "step": 0.01}),
                "èŒƒå›´å®½åº¦": ("FLOAT", {"default": 30.0, "min": 10.0, "max": 90.0, "step": 1.0}),
                "ç¾½åŒ–ç¨‹åº¦": ("FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}),
            }
        }

    RETURN_TYPES = ("IMAGE",)
    FUNCTION = "adjust_selective_color"
    CATEGORY = "ğŸ³Pond/é¢œè‰²"

    def adjust_selective_color(self, image, ç›®æ ‡é¢œè‰², è‰²ç›¸åç§», é¥±å’Œåº¦è°ƒæ•´, 
                              æ˜åº¦è°ƒæ•´, èŒƒå›´å®½åº¦, ç¾½åŒ–ç¨‹åº¦):
        
        # å®šä¹‰å„é¢œè‰²çš„ä¸­å¿ƒè‰²ç›¸å€¼
        color_hues = {
            "çº¢è‰²": 0,
            "é»„è‰²": 60,
            "ç»¿è‰²": 120,
            "é’è‰²": 180,
            "è“è‰²": 240,
            "å“çº¢": 300,
            "ç™½è‰²": -1,  # ç‰¹æ®Šå¤„ç†
            "é»‘è‰²": -2   # ç‰¹æ®Šå¤„ç†
        }
        
        batch_size = image.shape[0]
        result_images = []
        
        for i in range(batch_size):
            img_array = image[i].cpu().numpy()
            
            if ç›®æ ‡é¢œè‰² in ["ç™½è‰²", "é»‘è‰²"]:
                # åŸºäºäº®åº¦çš„é€‰æ‹©
                result = self.adjust_by_luminance(
                    img_array, ç›®æ ‡é¢œè‰², é¥±å’Œåº¦è°ƒæ•´, æ˜åº¦è°ƒæ•´, ç¾½åŒ–ç¨‹åº¦
                )
            else:
                # åŸºäºè‰²ç›¸çš„é€‰æ‹©
                target_hue = color_hues[ç›®æ ‡é¢œè‰²]
                result = self.adjust_by_hue(
                    img_array, target_hue, è‰²ç›¸åç§», é¥±å’Œåº¦è°ƒæ•´, 
                    æ˜åº¦è°ƒæ•´, èŒƒå›´å®½åº¦, ç¾½åŒ–ç¨‹åº¦
                )
            
            result_images.append(result)
        
        result_tensor = torch.from_numpy(np.stack(result_images))
        return (result_tensor,)
    
    def adjust_by_hue(self, image, target_hue, hue_shift, sat_adjust, 
                     val_adjust, range_width, feather):
        """åŸºäºè‰²ç›¸çš„é€‰æ‹©æ€§è°ƒæ•´"""
        # è½¬æ¢åˆ°HSV
        img_uint8 = (image * 255).astype(np.uint8)
        hsv = cv2.cvtColor(img_uint8, cv2.COLOR_RGB2HSV).astype(np.float32)
        
        # åˆ›å»ºè‰²ç›¸æ©æ¨¡
        hue_mask = self.create_hue_mask(hsv[:, :, 0], target_hue, range_width, feather)
        
        # åº”ç”¨è°ƒæ•´
        hsv[:, :, 0] = hsv[:, :, 0] + hue_mask * hue_shift
        hsv[:, :, 1] = hsv[:, :, 1] * (1 + hue_mask * sat_adjust)
        hsv[:, :, 2] = hsv[:, :, 2] * (1 + hue_mask * val_adjust)
        
        # é™åˆ¶èŒƒå›´
        hsv[:, :, 0] = hsv[:, :, 0] % 180
        hsv[:, :, 1] = np.clip(hsv[:, :, 1], 0, 255)
        hsv[:, :, 2] = np.clip(hsv[:, :, 2], 0, 255)
        
        # è½¬æ¢å›RGB
        result = cv2.cvtColor(hsv.astype(np.uint8), cv2.COLOR_HSV2RGB)
        return result.astype(np.float32) / 255.0
    
    def adjust_by_luminance(self, image, target, sat_adjust, val_adjust, feather):
        """åŸºäºäº®åº¦çš„é€‰æ‹©æ€§è°ƒæ•´"""
        # è®¡ç®—äº®åº¦
        gray = np.mean(image, axis=2)
        
        # åˆ›å»ºäº®åº¦æ©æ¨¡
        if target == "ç™½è‰²":
            mask = self.create_luminance_mask(gray, 0.7, 1.0, feather)
        else:  # é»‘è‰²
            mask = self.create_luminance_mask(gray, 0.0, 0.3, feather)
        
        # è½¬æ¢åˆ°HSVè¿›è¡Œè°ƒæ•´
        img_uint8 = (image * 255).astype(np.uint8)
        hsv = cv2.cvtColor(img_uint8, cv2.COLOR_RGB2HSV).astype(np.float32)
        
        # åº”ç”¨è°ƒæ•´
        hsv[:, :, 1] = hsv[:, :, 1] * (1 + mask * sat_adjust)
        hsv[:, :, 2] = hsv[:, :, 2] * (1 + mask * val_adjust)
        
        # é™åˆ¶èŒƒå›´
        hsv[:, :, 1] = np.clip(hsv[:, :, 1], 0, 255)
        hsv[:, :, 2] = np.clip(hsv[:, :, 2], 0, 255)
        
        # è½¬æ¢å›RGB
        result = cv2.cvtColor(hsv.astype(np.uint8), cv2.COLOR_HSV2RGB)
        return result.astype(np.float32) / 255.0
    
    def create_hue_mask(self, hue_channel, target_hue, range_width, feather):
        """åˆ›å»ºè‰²ç›¸é€‰æ‹©æ©æ¨¡"""
        # è®¡ç®—è‰²ç›¸å·®å¼‚
        hue_diff = np.abs(hue_channel - target_hue)
        hue_diff = np.minimum(hue_diff, 180 - hue_diff)  # å¤„ç†è‰²ç›¸ç¯ç»•
        
        # åˆ›å»ºæ©æ¨¡
        half_width = range_width / 2
        mask = np.zeros_like(hue_channel)
        
        # å®Œå…¨é€‰ä¸­çš„åŒºåŸŸ
        mask[hue_diff <= half_width * (1 - feather)] = 1
        
        # ç¾½åŒ–åŒºåŸŸ
        feather_start = half_width * (1 - feather)
        feather_end = half_width
        feather_mask = (hue_diff > feather_start) & (hue_diff <= feather_end)
        mask[feather_mask] = 1 - (hue_diff[feather_mask] - feather_start) / (feather_end - feather_start)
        
        return mask
    
    def create_luminance_mask(self, luminance, min_val, max_val, feather):
        """åˆ›å»ºäº®åº¦é€‰æ‹©æ©æ¨¡"""
        mask = np.zeros_like(luminance)
        
        # å®Œå…¨é€‰ä¸­çš„åŒºåŸŸ
        range_size = max_val - min_val
        inner_min = min_val + range_size * feather * 0.5
        inner_max = max_val - range_size * feather * 0.5
        
        mask[(luminance >= inner_min) & (luminance <= inner_max)] = 1
        
        # ä¸‹ç¾½åŒ–
        lower_feather = (luminance >= min_val) & (luminance < inner_min)
        mask[lower_feather] = (luminance[lower_feather] - min_val) / (inner_min - min_val)
        
        # ä¸Šç¾½åŒ–
        upper_feather = (luminance > inner_max) & (luminance <= max_val)
        mask[upper_feather] = 1 - (luminance[upper_feather] - inner_max) / (max_val - inner_max)
        
        return mask

# èŠ‚ç‚¹æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "ColorGradingNode": ColorGradingNode,
    "HDREffectNode": HDREffectNode,
    "SkinEnhancementNode": SkinEnhancementNode,
    "ArtisticEffectsNode": ArtisticEffectsNode,
    "SelectiveColorNode": SelectiveColorNode
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "ColorGradingNode": "ğŸ³è‰²å½©å¹³è¡¡",
    "HDREffectNode": "ğŸ³HDR",
    "SkinEnhancementNode": "ğŸ³äººåƒç¾åŒ–",
    "ArtisticEffectsNode": "ğŸ³è‰ºæœ¯æ•ˆæœ",
    "SelectiveColorNode": "ğŸ³è‰²å½©èŒƒå›´"
}