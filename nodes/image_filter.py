import torch
import numpy as np
from PIL import Image, ImageEnhance, ImageFilter
import cv2

class ImageFilterNode:
    """
    ComfyUIå›¾åƒæ»¤é•œè°ƒèŠ‚èŠ‚ç‚¹
    æ”¯æŒå¤šç§å›¾åƒæ»¤é•œæ•ˆæœï¼ŒåŒ…æ‹¬äº®åº¦ã€å¯¹æ¯”åº¦ã€é¥±å’Œåº¦ã€æ¨¡ç³Šã€é”åŒ–ç­‰
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),
                "äº®åº¦": ("FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0, "step": 0.01}),
                "å¯¹æ¯”åº¦": ("FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0, "step": 0.01}),
                "é¥±å’Œåº¦": ("FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0, "step": 0.01}),
                "é”åº¦": ("FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0, "step": 0.01}),
                "è‰²è°ƒåç§»": ("FLOAT", {"default": 0.0, "min": -180.0, "max": 180.0, "step": 1.0}),
                "æ¨¡ç³ŠåŠå¾„": ("INT", {"default": 0, "min": 0, "max": 20, "step": 1}),
                "è‰²æ¸©": ("FLOAT", {"default": 0.0, "min": -100.0, "max": 100.0, "step": 1.0}),
                "ä¼½é©¬å€¼": ("FLOAT", {"default": 1.0, "min": 0.1, "max": 3.0, "step": 0.01}),
            },
            "optional": {
                "æ»¤é•œç±»å‹": (["æ— ", "å¤å¤", "æ£•è¤è‰²", "ç°åº¦", "è¾¹ç¼˜å¢å¼º", "æµ®é›•"],),
            }
        }

    RETURN_TYPES = ("IMAGE",)
    FUNCTION = "apply_filters"
    CATEGORY = "ğŸ³Pond/image"

    def apply_filters(self, image, äº®åº¦=1.0, å¯¹æ¯”åº¦=1.0, é¥±å’Œåº¦=1.0, 
                     é”åº¦=1.0, è‰²è°ƒåç§»=0.0, æ¨¡ç³ŠåŠå¾„=0, è‰²æ¸©=0.0, 
                     ä¼½é©¬å€¼=1.0, æ»¤é•œç±»å‹="æ— "):
        
        # å°†tensorè½¬æ¢ä¸ºPIL Image
        batch_size = image.shape[0]
        result_images = []
        
        for i in range(batch_size):
            # ä»tensorè½¬æ¢ä¸ºnumpyæ•°ç»„
            img_array = image[i].cpu().numpy()
            img_array = (img_array * 255).astype(np.uint8)
            
            # è½¬æ¢ä¸ºPIL Image
            pil_image = Image.fromarray(img_array, mode='RGB')
            
            # åº”ç”¨åŸºç¡€è°ƒæ•´
            # äº®åº¦è°ƒæ•´
            if äº®åº¦ != 1.0:
                enhancer = ImageEnhance.Brightness(pil_image)
                pil_image = enhancer.enhance(äº®åº¦)
            
            # å¯¹æ¯”åº¦è°ƒæ•´
            if å¯¹æ¯”åº¦ != 1.0:
                enhancer = ImageEnhance.Contrast(pil_image)
                pil_image = enhancer.enhance(å¯¹æ¯”åº¦)
            
            # é¥±å’Œåº¦è°ƒæ•´
            if é¥±å’Œåº¦ != 1.0:
                enhancer = ImageEnhance.Color(pil_image)
                pil_image = enhancer.enhance(é¥±å’Œåº¦)
            
            # é”åº¦è°ƒæ•´
            if é”åº¦ != 1.0:
                enhancer = ImageEnhance.Sharpness(pil_image)
                pil_image = enhancer.enhance(é”åº¦)
            
            # è‰²è°ƒè°ƒæ•´
            if è‰²è°ƒåç§» != 0.0:
                pil_image = self.adjust_hue(pil_image, è‰²è°ƒåç§»)
            
            # æ¨¡ç³Šæ•ˆæœ
            if æ¨¡ç³ŠåŠå¾„ > 0:
                pil_image = pil_image.filter(ImageFilter.GaussianBlur(radius=æ¨¡ç³ŠåŠå¾„))
            
            # è‰²æ¸©è°ƒæ•´
            if è‰²æ¸© != 0.0:
                pil_image = self.adjust_temperature(pil_image, è‰²æ¸©)
            
            # Gammaæ ¡æ­£
            if ä¼½é©¬å€¼ != 1.0:
                pil_image = self.adjust_gamma(pil_image, ä¼½é©¬å€¼)
            
            # åº”ç”¨ç‰¹æ®Šæ»¤é•œ
            if æ»¤é•œç±»å‹ != "æ— ":
                pil_image = self.apply_special_filter(pil_image, æ»¤é•œç±»å‹)
            
            # è½¬æ¢å›tensor
            img_array = np.array(pil_image).astype(np.float32) / 255.0
            result_images.append(img_array)
        
        # ç»„åˆæ‰¹æ¬¡
        result_tensor = torch.from_numpy(np.stack(result_images))
        
        return (result_tensor,)
    
    def adjust_hue(self, image, hue_shift):
        """è°ƒæ•´è‰²è°ƒ"""
        # è½¬æ¢ä¸ºHSV
        img_array = np.array(image)
        hsv = cv2.cvtColor(img_array, cv2.COLOR_RGB2HSV).astype(np.float32)
        
        # è°ƒæ•´è‰²è°ƒ
        hsv[:, :, 0] = (hsv[:, :, 0] + hue_shift) % 360
        
        # è½¬æ¢å›RGB
        hsv = hsv.astype(np.uint8)
        rgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)
        
        return Image.fromarray(rgb)
    
    def adjust_temperature(self, image, temperature):
        """è°ƒæ•´è‰²æ¸©"""
        img_array = np.array(image).astype(np.float32)
        
        # è‰²æ¸©è°ƒæ•´ç³»æ•°
        temp_scale = temperature / 100.0
        
        # è°ƒæ•´çº¢è‰²å’Œè“è‰²é€šé“
        img_array[:, :, 0] *= (1 + temp_scale * 0.3)  # çº¢è‰²é€šé“
        img_array[:, :, 2] *= (1 - temp_scale * 0.3)  # è“è‰²é€šé“
        
        # é™åˆ¶èŒƒå›´
        img_array = np.clip(img_array, 0, 255).astype(np.uint8)
        
        return Image.fromarray(img_array)
    
    def adjust_gamma(self, image, gamma):
        """Gammaæ ¡æ­£"""
        img_array = np.array(image).astype(np.float32) / 255.0
        
        # åº”ç”¨gammaæ ¡æ­£
        img_array = np.power(img_array, gamma)
        
        # è½¬æ¢å›0-255èŒƒå›´
        img_array = (img_array * 255).astype(np.uint8)
        
        return Image.fromarray(img_array)
    
    def apply_special_filter(self, image, filter_type):
        """åº”ç”¨ç‰¹æ®Šæ»¤é•œæ•ˆæœ"""
        if filter_type == "å¤å¤":
            # å¤å¤æ•ˆæœ
            img_array = np.array(image).astype(np.float32)
            # è°ƒæ•´è‰²è°ƒï¼Œå¢åŠ é»„è‰²è°ƒ
            img_array[:, :, 0] *= 1.1  # çº¢è‰²
            img_array[:, :, 1] *= 1.0  # ç»¿è‰²
            img_array[:, :, 2] *= 0.8  # è“è‰²
            # é™ä½å¯¹æ¯”åº¦
            img_array = (img_array - 128) * 0.8 + 128
            img_array = np.clip(img_array, 0, 255).astype(np.uint8)
            return Image.fromarray(img_array)
        
        elif filter_type == "æ£•è¤è‰²":
            # æ£•è¤è‰²æ•ˆæœ
            img_array = np.array(image).astype(np.float32)
            r = img_array[:, :, 0]
            g = img_array[:, :, 1]
            b = img_array[:, :, 2]
            
            tr = 0.393 * r + 0.769 * g + 0.189 * b
            tg = 0.349 * r + 0.686 * g + 0.168 * b
            tb = 0.272 * r + 0.534 * g + 0.131 * b
            
            img_array[:, :, 0] = tr
            img_array[:, :, 1] = tg
            img_array[:, :, 2] = tb
            
            img_array = np.clip(img_array, 0, 255).astype(np.uint8)
            return Image.fromarray(img_array)
        
        elif filter_type == "ç°åº¦":
            # ç°åº¦æ•ˆæœ
            return image.convert('L').convert('RGB')
        
        elif filter_type == "è¾¹ç¼˜å¢å¼º":
            # è¾¹ç¼˜å¢å¼º
            return image.filter(ImageFilter.EDGE_ENHANCE_MORE)
        
        elif filter_type == "æµ®é›•":
            # æµ®é›•æ•ˆæœ
            return image.filter(ImageFilter.EMBOSS)
        
        return image


# é«˜çº§æ»¤é•œèŠ‚ç‚¹
class AdvancedImageFilterNode:
    """
    é«˜çº§å›¾åƒæ»¤é•œèŠ‚ç‚¹ï¼Œæä¾›æ›´å¤šä¸“ä¸šæ»¤é•œæ•ˆæœ
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),
                "æ™•å½±å¼ºåº¦": ("FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01}),
                "è‰²å·®": ("FLOAT", {"default": 0.0, "min": 0.0, "max": 10.0, "step": 0.1}),
                "å™ªç‚¹å¼ºåº¦": ("FLOAT", {"default": 0.0, "min": 0.0, "max": 0.5, "step": 0.01}),
                "èƒ¶ç‰‡é¢—ç²’": ("FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01}),
                "æ³›å…‰å¼ºåº¦": ("FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01}),
                "æ³›å…‰é˜ˆå€¼": ("FLOAT", {"default": 0.8, "min": 0.0, "max": 1.0, "step": 0.01}),
            }
        }
    
    RETURN_TYPES = ("IMAGE",)
    FUNCTION = "apply_advanced_filters"
    CATEGORY = "ğŸ³Pond/image"
    
    def apply_advanced_filters(self, image, æ™•å½±å¼ºåº¦=0.0, è‰²å·®=0.0,
                              å™ªç‚¹å¼ºåº¦=0.0, èƒ¶ç‰‡é¢—ç²’=0.0, æ³›å…‰å¼ºåº¦=0.0, æ³›å…‰é˜ˆå€¼=0.8):
        
        batch_size = image.shape[0]
        result_images = []
        
        for i in range(batch_size):
            img_array = image[i].cpu().numpy()
            img_array = (img_array * 255).astype(np.uint8)
            
            # åº”ç”¨æ™•å½±æ•ˆæœ
            if æ™•å½±å¼ºåº¦ > 0:
                img_array = self.apply_vignette(img_array, æ™•å½±å¼ºåº¦)
            
            # åº”ç”¨è‰²å·®æ•ˆæœ
            if è‰²å·® > 0:
                img_array = self.apply_chromatic_aberration(img_array, è‰²å·®)
            
            # åº”ç”¨å™ªç‚¹
            if å™ªç‚¹å¼ºåº¦ > 0:
                img_array = self.apply_noise(img_array, å™ªç‚¹å¼ºåº¦)
            
            # åº”ç”¨èƒ¶ç‰‡é¢—ç²’
            if èƒ¶ç‰‡é¢—ç²’ > 0:
                img_array = self.apply_film_grain(img_array, èƒ¶ç‰‡é¢—ç²’)
            
            # åº”ç”¨æ³›å…‰æ•ˆæœ
            if æ³›å…‰å¼ºåº¦ > 0:
                img_array = self.apply_bloom(img_array, æ³›å…‰å¼ºåº¦, æ³›å…‰é˜ˆå€¼)
            
            # è½¬æ¢å›tensor
            img_array = img_array.astype(np.float32) / 255.0
            result_images.append(img_array)
        
        result_tensor = torch.from_numpy(np.stack(result_images))
        return (result_tensor,)
    
    def apply_vignette(self, image, strength):
        """åº”ç”¨æ™•å½±æ•ˆæœ"""
        h, w = image.shape[:2]
        
        # åˆ›å»ºå¾„å‘æ¸å˜
        center_x, center_y = w // 2, h // 2
        Y, X = np.ogrid[:h, :w]
        dist = np.sqrt((X - center_x)**2 + (Y - center_y)**2)
        max_dist = np.sqrt(center_x**2 + center_y**2)
        
        # åˆ›å»ºæ™•å½±é®ç½©
        vignette = 1 - (dist / max_dist) * strength
        vignette = np.clip(vignette, 0, 1)
        vignette = vignette[:, :, np.newaxis]
        
        # åº”ç”¨æ™•å½±
        result = image.astype(np.float32) * vignette
        return result.astype(np.uint8)
    
    def apply_chromatic_aberration(self, image, amount):
        """åº”ç”¨è‰²å·®æ•ˆæœ"""
        h, w = image.shape[:2]
        
        # åˆ†ç¦»é€šé“
        r, g, b = cv2.split(image)
        
        # åˆ›å»ºä½ç§»
        shift = int(amount)
        
        # ç§»åŠ¨çº¢è‰²å’Œè“è‰²é€šé“
        M_r = np.float32([[1, 0, shift], [0, 1, 0]])
        M_b = np.float32([[1, 0, -shift], [0, 1, 0]])
        
        r_shifted = cv2.warpAffine(r, M_r, (w, h))
        b_shifted = cv2.warpAffine(b, M_b, (w, h))
        
        # åˆå¹¶é€šé“
        result = cv2.merge([r_shifted, g, b_shifted])
        return result
    
    def apply_noise(self, image, amount):
        """åº”ç”¨å™ªç‚¹"""
        noise = np.random.normal(0, amount * 255, image.shape)
        noisy_image = image.astype(np.float32) + noise
        return np.clip(noisy_image, 0, 255).astype(np.uint8)
    
    def apply_film_grain(self, image, intensity):
        """åº”ç”¨èƒ¶ç‰‡é¢—ç²’æ•ˆæœ"""
        h, w = image.shape[:2]
        
        # åˆ›å»ºé¢—ç²’çº¹ç†
        grain = np.random.normal(0, 1, (h, w))
        grain = cv2.GaussianBlur(grain, (3, 3), 0)
        grain = grain * intensity * 50
        
        # åº”ç”¨åˆ°æ¯ä¸ªé€šé“
        result = image.astype(np.float32)
        for c in range(3):
            result[:, :, c] += grain
        
        return np.clip(result, 0, 255).astype(np.uint8)
    
    def apply_bloom(self, image, intensity, threshold):
        """åº”ç”¨æ³›å…‰æ•ˆæœ"""
        # æå–äº®éƒ¨
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        _, bright_mask = cv2.threshold(gray, int(threshold * 255), 255, cv2.THRESH_BINARY)
        
        # åˆ›å»ºæ³›å…‰
        bloom = cv2.bitwise_and(image, image, mask=bright_mask)
        bloom = cv2.GaussianBlur(bloom, (21, 21), 0)
        
        # æ··åˆåŸå›¾å’Œæ³›å…‰
        result = cv2.addWeighted(image, 1, bloom, intensity, 0)
        return np.clip(result, 0, 255).astype(np.uint8)


# èŠ‚ç‚¹æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "ImageFilterNode": ImageFilterNode,
    "AdvancedImageFilterNode": AdvancedImageFilterNode
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "ImageFilterNode": "ğŸ³æ»¤é•œè°ƒèŠ‚",
    "AdvancedImageFilterNode": "ğŸ³æ»¤é•œè°ƒèŠ‚V2"
}