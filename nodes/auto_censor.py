import torch
import numpy as np
from PIL import Image, ImageFilter
import cv2
from typing import Tuple, Optional
import os
import sys

# å¯¼å…¥ComfyUIç›¸å…³æ¨¡å—
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

class AutoCensorWithOpenPose:
    """
    ä½¿ç”¨OpenPoseæ£€æµ‹éª¨éª¼å¹¶è‡ªåŠ¨æ‰“ç çš„èŠ‚ç‚¹
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE", {"tooltip": "è¾“å…¥éœ€è¦å¤„ç†çš„å›¾åƒ"}),
                "censor_face": ("BOOLEAN", {
                    "default": False,
                    "label_on": "æ‰“ç è„¸éƒ¨",
                    "label_off": "ä¸æ‰“ç è„¸éƒ¨",
                    "tooltip": "æ˜¯å¦å¯¹è„¸éƒ¨è¿›è¡Œæ‰“ç "
                }),
                "censor_chest": ("BOOLEAN", {
                    "default": True,
                    "label_on": "æ‰“ç èƒ¸éƒ¨",
                    "label_off": "ä¸æ‰“ç èƒ¸éƒ¨",
                    "tooltip": "æ˜¯å¦å¯¹èƒ¸éƒ¨åŒºåŸŸè¿›è¡Œæ‰“ç "
                }),
                "censor_groin": ("BOOLEAN", {
                    "default": True,
                    "label_on": "æ‰“ç è…¿æ ¹éƒ¨",
                    "label_off": "ä¸æ‰“ç è…¿æ ¹éƒ¨",
                    "tooltip": "æ˜¯å¦å¯¹è…¿æ ¹éƒ¨åŒºåŸŸè¿›è¡Œæ‰“ç "
                }),
                "blur_strength": ("INT", {
                    "default": 20,
                    "min": 5,
                    "max": 50,
                    "step": 5,
                    "display": "slider",
                    "tooltip": "æ¨¡ç³Šå¼ºåº¦ï¼Œæ•°å€¼è¶Šå¤§æ¨¡ç³Šæ•ˆæžœè¶Šå¼º"
                }),
                "censor_size_multiplier": ("FLOAT", {
                    "default": 1.2,
                    "min": 0.8,
                    "max": 2.0,
                    "step": 0.1,
                    "display": "slider",
                    "tooltip": "æ‰“ç åŒºåŸŸå¤§å°å€æ•°ï¼Œç”¨äºŽè°ƒæ•´æ‰“ç èŒƒå›´"
                }),
            },
        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("æ‰“ç åŽçš„å›¾åƒ",)
    FUNCTION = "process_image"
    CATEGORY = "ðŸ³Pond/image"

    def __init__(self):
        # OpenPoseå…³é”®ç‚¹ç´¢å¼•
        self.POSE_BODY_25_BODY_PARTS = {
            "Nose": 0,
            "Neck": 1,
            "RShoulder": 2,
            "RElbow": 3,
            "RWrist": 4,
            "LShoulder": 5,
            "LElbow": 6,
            "LWrist": 7,
            "MidHip": 8,
            "RHip": 9,
            "RKnee": 10,
            "RAnkle": 11,
            "LHip": 12,
            "LKnee": 13,
            "LAnkle": 14,
            "REye": 15,
            "LEye": 16,
            "REar": 17,
            "LEar": 18,
            "LBigToe": 19,
            "LSmallToe": 20,
            "LHeel": 21,
            "RBigToe": 22,
            "RSmallToe": 23,
            "RHeel": 24
        }

    def detect_openpose_keypoints(self, image_np):
        """
        ä½¿ç”¨MediaPipeæ£€æµ‹äººä½“å…³é”®ç‚¹å¹¶æ˜ å°„åˆ°OpenPoseæ ¼å¼
        """
        try:
            import mediapipe as mp
            
            # åˆå§‹åŒ–MediaPipe
            mp_pose = mp.solutions.pose
            pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5)
            
            # è½¬æ¢å›¾åƒæ ¼å¼
            image_rgb = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)
            results = pose.process(image_rgb)
            
            h, w = image_np.shape[:2]
            keypoints = np.zeros((25, 3))  # OpenPose BODY_25æ ¼å¼
            
            if results.pose_landmarks:
                # MediaPipeåˆ°OpenPoseçš„æ˜ å°„
                mp_to_op_mapping = {
                    0: 0,   # NOSE -> Nose
                    11: 5,  # LEFT_SHOULDER -> LShoulder
                    12: 2,  # RIGHT_SHOULDER -> RShoulder
                    23: 12, # LEFT_HIP -> LHip
                    24: 9,  # RIGHT_HIP -> RHip
                    25: 13, # LEFT_KNEE -> LKnee
                    26: 10, # RIGHT_KNEE -> RKnee
                    2: 16,  # LEFT_EYE -> LEye
                    5: 15,  # RIGHT_EYE -> REye
                    7: 18,  # LEFT_EAR -> LEar
                    8: 17,  # RIGHT_EAR -> REar
                }
                
                # æ˜ å°„å…³é”®ç‚¹
                for mp_idx, op_idx in mp_to_op_mapping.items():
                    if mp_idx < len(results.pose_landmarks.landmark):
                        landmark = results.pose_landmarks.landmark[mp_idx]
                        keypoints[op_idx] = [
                            landmark.x * w,
                            landmark.y * h,
                            landmark.visibility
                        ]
                
                # è®¡ç®—é¢å¤–çš„å…³é”®ç‚¹
                # Neck (OpenPose idx 1) - ä¸¤è‚©è†€ä¸­ç‚¹
                if keypoints[2][2] > 0.1 and keypoints[5][2] > 0.1:
                    keypoints[1] = [
                        (keypoints[2][0] + keypoints[5][0]) / 2,
                        (keypoints[2][1] + keypoints[5][1]) / 2,
                        (keypoints[2][2] + keypoints[5][2]) / 2
                    ]
                
                # MidHip (OpenPose idx 8) - ä¸¤è‡€éƒ¨ä¸­ç‚¹
                if keypoints[9][2] > 0.1 and keypoints[12][2] > 0.1:
                    keypoints[8] = [
                        (keypoints[9][0] + keypoints[12][0]) / 2,
                        (keypoints[9][1] + keypoints[12][1]) / 2,
                        (keypoints[9][2] + keypoints[12][2]) / 2
                    ]
            
            pose.close()
            return keypoints
            
        except ImportError:
            print("MediaPipeæœªå®‰è£…ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ã€‚è¯·è¿è¡Œ: pip install mediapipe")
            print("è­¦å‘Šï¼šå½“å‰ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæµ‹è¯•ï¼Œå®žé™…ä½¿ç”¨æ—¶è¯·å®‰è£…MediaPipe")
            # è¿”å›žæ¨¡æ‹Ÿæ•°æ®ç”¨äºŽæµ‹è¯•
            h, w = image_np.shape[:2]
            keypoints = np.zeros((25, 3))
            # æ¨¡æ‹Ÿä¸€äº›å…³é”®ç‚¹ç”¨äºŽæµ‹è¯•
            keypoints[0] = [w/2, h*0.15, 0.9]  # Nose
            keypoints[1] = [w/2, h*0.2, 0.9]  # Neck
            keypoints[2] = [w*0.4, h*0.25, 0.9]  # RShoulder  
            keypoints[5] = [w*0.6, h*0.25, 0.9]  # LShoulder
            keypoints[8] = [w/2, h*0.5, 0.9]  # MidHip
            keypoints[9] = [w*0.45, h*0.5, 0.9]  # RHip
            keypoints[12] = [w*0.55, h*0.5, 0.9]  # LHip
            keypoints[15] = [w*0.45, h*0.12, 0.9]  # REye
            keypoints[16] = [w*0.55, h*0.12, 0.9]  # LEye
            return keypoints

    def get_face_region(self, keypoints, image_shape, size_multiplier):
        """
        æ ¹æ®é¢éƒ¨å…³é”®ç‚¹è®¡ç®—è„¸éƒ¨åŒºåŸŸ
        """
        h, w = image_shape[:2]
        
        # èŽ·å–é¢éƒ¨ç›¸å…³å…³é”®ç‚¹
        nose = keypoints[self.POSE_BODY_25_BODY_PARTS["Nose"]]
        neck = keypoints[self.POSE_BODY_25_BODY_PARTS["Neck"]]
        left_eye = keypoints[self.POSE_BODY_25_BODY_PARTS["LEye"]]
        right_eye = keypoints[self.POSE_BODY_25_BODY_PARTS["REye"]]
        left_ear = keypoints[self.POSE_BODY_25_BODY_PARTS["LEar"]]
        right_ear = keypoints[self.POSE_BODY_25_BODY_PARTS["REar"]]
        
        # æ£€æŸ¥å…³é”®ç‚¹æ˜¯å¦æœ‰æ•ˆ
        if nose[2] > 0.1:
            # è®¡ç®—è„¸éƒ¨ä¸­å¿ƒï¼ˆä½¿ç”¨é¼»å­ä½ç½®ï¼‰
            face_center_x = nose[0]
            face_center_y = nose[1]
            
            # ä¼°ç®—è„¸éƒ¨å¤§å°
            face_width = 0
            face_height = 0
            
            # å¦‚æžœæœ‰çœ¼ç›å…³é”®ç‚¹ï¼Œä½¿ç”¨çœ¼ç›é—´è·ä¼°ç®—å®½åº¦
            if left_eye[2] > 0.1 and right_eye[2] > 0.1:
                eye_distance = abs(right_eye[0] - left_eye[0])
                face_width = eye_distance * 2.5
            # å¦‚æžœæœ‰è€³æœµå…³é”®ç‚¹ï¼Œä½¿ç”¨è€³æœµé—´è·
            elif left_ear[2] > 0.1 and right_ear[2] > 0.1:
                ear_distance = abs(right_ear[0] - left_ear[0])
                face_width = ear_distance * 1.2
            # å¦åˆ™ä½¿ç”¨é»˜è®¤ä¼°ç®—
            else:
                face_width = w * 0.15  # å‡è®¾è„¸å®½çº¦ä¸ºå›¾åƒå®½åº¦çš„15%
            
            # å¦‚æžœæœ‰é¢ˆéƒ¨å…³é”®ç‚¹ï¼Œä½¿ç”¨å®ƒæ¥ä¼°ç®—é«˜åº¦
            if neck[2] > 0.1:
                face_height = abs(neck[1] - nose[1]) * 2.5
            else:
                face_height = face_width * 1.3  # è„¸éƒ¨é«˜åº¦é€šå¸¸æ˜¯å®½åº¦çš„1.3å€
            
            # åº”ç”¨å¤§å°å€æ•°
            face_width *= size_multiplier
            face_height *= size_multiplier
            
            # è®¡ç®—è¾¹ç•Œæ¡†ï¼Œç¨å¾®å‘ä¸Šåç§»ä»¥æ›´å¥½åœ°è¦†ç›–é¢å¤´
            x1 = int(max(0, face_center_x - face_width/2))
            y1 = int(max(0, face_center_y - face_height/2 - face_height*0.2))
            x2 = int(min(w, face_center_x + face_width/2))
            y2 = int(min(h, face_center_y + face_height/2))
            
            return (x1, y1, x2, y2)
        
        return None

    def get_chest_region(self, keypoints, image_shape, size_multiplier):
        """
        æ ¹æ®è‚©è†€å’Œè‡€éƒ¨å…³é”®ç‚¹è®¡ç®—èƒ¸éƒ¨åŒºåŸŸ
        """
        h, w = image_shape[:2]
        
        # èŽ·å–ç›¸å…³å…³é”®ç‚¹
        left_shoulder = keypoints[self.POSE_BODY_25_BODY_PARTS["LShoulder"]]
        right_shoulder = keypoints[self.POSE_BODY_25_BODY_PARTS["RShoulder"]]
        mid_hip = keypoints[self.POSE_BODY_25_BODY_PARTS["MidHip"]]
        neck = keypoints[self.POSE_BODY_25_BODY_PARTS["Neck"]]
        
        # æ£€æŸ¥å…³é”®ç‚¹æ˜¯å¦æœ‰æ•ˆ
        if (left_shoulder[2] > 0.1 and right_shoulder[2] > 0.1 and 
            mid_hip[2] > 0.1 and neck[2] > 0.1):
            
            # è®¡ç®—èƒ¸éƒ¨ä¸­å¿ƒä½ç½®
            chest_x = (left_shoulder[0] + right_shoulder[0]) / 2
            chest_y = (neck[1] + mid_hip[1]) / 2
            
            # è®¡ç®—èƒ¸éƒ¨åŒºåŸŸå¤§å°
            shoulder_width = abs(right_shoulder[0] - left_shoulder[0])
            chest_height = abs(mid_hip[1] - neck[1]) * 0.4
            
            # åº”ç”¨å¤§å°å€æ•°
            width = shoulder_width * size_multiplier
            height = chest_height * size_multiplier
            
            # è®¡ç®—è¾¹ç•Œæ¡†
            x1 = int(max(0, chest_x - width/2))
            y1 = int(max(0, chest_y - height/2))
            x2 = int(min(w, chest_x + width/2))
            y2 = int(min(h, chest_y + height/2))
            
            return (x1, y1, x2, y2)
        
        return None

    def get_groin_region(self, keypoints, image_shape, size_multiplier):
        """
        æ ¹æ®è‡€éƒ¨å’Œè†ç›–å…³é”®ç‚¹è®¡ç®—è…¿æ ¹éƒ¨åŒºåŸŸ
        """
        h, w = image_shape[:2]
        
        # èŽ·å–ç›¸å…³å…³é”®ç‚¹
        mid_hip = keypoints[self.POSE_BODY_25_BODY_PARTS["MidHip"]]
        left_hip = keypoints[self.POSE_BODY_25_BODY_PARTS["LHip"]]
        right_hip = keypoints[self.POSE_BODY_25_BODY_PARTS["RHip"]]
        left_knee = keypoints[self.POSE_BODY_25_BODY_PARTS["LKnee"]]
        right_knee = keypoints[self.POSE_BODY_25_BODY_PARTS["RKnee"]]
        
        # æ£€æŸ¥å…³é”®ç‚¹æ˜¯å¦æœ‰æ•ˆ
        if (mid_hip[2] > 0.1 and left_hip[2] > 0.1 and right_hip[2] > 0.1):
            
            # è®¡ç®—è…¿æ ¹éƒ¨ä¸­å¿ƒä½ç½®
            groin_x = mid_hip[0]
            groin_y = mid_hip[1]
            
            # å¦‚æžœè†ç›–å…³é”®ç‚¹æœ‰æ•ˆï¼Œä½¿ç”¨å®ƒä»¬æ¥è°ƒæ•´ä½ç½®
            if left_knee[2] > 0.1 and right_knee[2] > 0.1:
                knee_y = (left_knee[1] + right_knee[1]) / 2
                groin_y = (mid_hip[1] + knee_y) / 2
            
            # è®¡ç®—è…¿æ ¹éƒ¨åŒºåŸŸå¤§å°
            hip_width = abs(right_hip[0] - left_hip[0])
            groin_height = hip_width * 0.8
            
            # åº”ç”¨å¤§å°å€æ•°
            width = hip_width * size_multiplier
            height = groin_height * size_multiplier
            
            # è®¡ç®—è¾¹ç•Œæ¡†
            x1 = int(max(0, groin_x - width/2))
            y1 = int(max(0, groin_y - height/2))
            x2 = int(min(w, groin_x + width/2))
            y2 = int(min(h, groin_y + height/2))
            
            return (x1, y1, x2, y2)
        
        return None

    def apply_blur(self, image, region, blur_strength):
        """
        å¯¹æŒ‡å®šåŒºåŸŸåº”ç”¨æ¨¡ç³Šæ•ˆæžœ
        """
        if region is None:
            return image
        
        x1, y1, x2, y2 = region
        
        # æå–åŒºåŸŸ
        region_img = image[y1:y2, x1:x2]
        
        # åº”ç”¨é«˜æ–¯æ¨¡ç³Š
        blurred_region = cv2.GaussianBlur(region_img, (blur_strength*2+1, blur_strength*2+1), 0)
        
        # å°†æ¨¡ç³ŠåŒºåŸŸæ”¾å›žåŽŸå›¾
        result = image.copy()
        result[y1:y2, x1:x2] = blurred_region
        
        return result

    def apply_elliptical_blur(self, image, region, blur_strength, is_face=False):
        """
        å¯¹æŒ‡å®šåŒºåŸŸåº”ç”¨æ¤­åœ†å½¢æ¨¡ç³Šæ•ˆæžœï¼ˆç”¨äºŽè„¸éƒ¨ç­‰éœ€è¦æ›´è‡ªç„¶æ•ˆæžœçš„åŒºåŸŸï¼‰
        """
        if region is None:
            return image
        
        x1, y1, x2, y2 = region
        center_x = (x1 + x2) // 2
        center_y = (y1 + y2) // 2
        width = x2 - x1
        height = y2 - y1
        
        # åˆ›å»ºæ¤­åœ†å½¢é®ç½©
        mask = np.zeros(image.shape[:2], dtype=np.uint8)
        cv2.ellipse(mask, (center_x, center_y), (width//2, height//2), 0, 0, 360, 255, -1)
        
        # åˆ›å»ºæ¨¡ç³Šç‰ˆæœ¬
        blurred = cv2.GaussianBlur(image, (blur_strength*2+1, blur_strength*2+1), 0)
        
        # ä½¿ç”¨é®ç½©æ··åˆåŽŸå›¾å’Œæ¨¡ç³Šå›¾
        result = image.copy()
        mask_3channel = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR) / 255.0
        result = (1 - mask_3channel) * image + mask_3channel * blurred
        
        return result.astype(np.uint8)

    def process_image(self, image, censor_face, censor_chest, censor_groin, blur_strength, censor_size_multiplier):
        """
        å¤„ç†å›¾åƒçš„ä¸»å‡½æ•°
        """
        # å‚æ•°éªŒè¯
        if not censor_face and not censor_chest and not censor_groin:
            print("æç¤ºï¼šæœªé€‰æ‹©ä»»ä½•æ‰“ç åŒºåŸŸï¼Œå°†è¿”å›žåŽŸå›¾")
            return (image,)
        
        # è½¬æ¢å›¾åƒæ ¼å¼
        image_np = (image.squeeze(0).cpu().numpy() * 255).astype(np.uint8)
        
        # æ£€æµ‹OpenPoseå…³é”®ç‚¹
        print("æ­£åœ¨æ£€æµ‹äººä½“å§¿æ€...")
        keypoints = self.detect_openpose_keypoints(image_np)
        
        # æ£€æŸ¥æ˜¯å¦æ£€æµ‹åˆ°äººä½“
        valid_keypoints = np.sum(keypoints[:, 2] > 0.1)
        if valid_keypoints < 3:
            print("è­¦å‘Šï¼šæœªæ£€æµ‹åˆ°æœ‰æ•ˆçš„äººä½“å§¿æ€ï¼Œè¯·ç¡®ä¿å›¾åƒä¸­åŒ…å«æ¸…æ™°çš„äººä½“")
            return (image,)
        
        # æ ¹æ®é€‰é¡¹å†³å®šè¦æ‰“ç çš„åŒºåŸŸ
        regions_to_blur = []
        face_region = None
        chest_region = None
        groin_region = None
        
        if censor_face:
            print("æ­£åœ¨å®šä½è„¸éƒ¨åŒºåŸŸ...")
            face_region = self.get_face_region(keypoints, image_np.shape, censor_size_multiplier)
            if face_region:
                regions_to_blur.append(face_region)
                print("âœ“ æˆåŠŸå®šä½è„¸éƒ¨åŒºåŸŸ")
            else:
                print("âœ— æ— æ³•å®šä½è„¸éƒ¨åŒºåŸŸ")
        
        if censor_chest:
            print("æ­£åœ¨å®šä½èƒ¸éƒ¨åŒºåŸŸ...")
            chest_region = self.get_chest_region(keypoints, image_np.shape, censor_size_multiplier)
            if chest_region:
                regions_to_blur.append(chest_region)
                print("âœ“ æˆåŠŸå®šä½èƒ¸éƒ¨åŒºåŸŸ")
            else:
                print("âœ— æ— æ³•å®šä½èƒ¸éƒ¨åŒºåŸŸ")
        
        if censor_groin:
            print("æ­£åœ¨å®šä½è…¿æ ¹éƒ¨åŒºåŸŸ...")
            groin_region = self.get_groin_region(keypoints, image_np.shape, censor_size_multiplier)
            if groin_region:
                regions_to_blur.append(groin_region)
                print("âœ“ æˆåŠŸå®šä½è…¿æ ¹éƒ¨åŒºåŸŸ")
            else:
                print("âœ— æ— æ³•å®šä½è…¿æ ¹éƒ¨åŒºåŸŸ")
        
        # å¦‚æžœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•åŒºåŸŸ
        if not regions_to_blur:
            print("è­¦å‘Šï¼šæœªèƒ½å®šä½ä»»ä½•éœ€è¦æ‰“ç çš„åŒºåŸŸ")
            return (image,)
        
        # åº”ç”¨æ¨¡ç³Šæ•ˆæžœ
        print(f"æ­£åœ¨åº”ç”¨æ¨¡ç³Šæ•ˆæžœï¼ˆå¼ºåº¦ï¼š{blur_strength}ï¼‰...")
        result_image = image_np.copy()
        
        # åˆ†åˆ«å¤„ç†ä¸åŒç±»åž‹çš„åŒºåŸŸ
        region_index = 0
        
        # å¤„ç†è„¸éƒ¨ï¼ˆä½¿ç”¨æ¤­åœ†å½¢æ¨¡ç³Šï¼‰
        if censor_face and face_region:
            result_image = self.apply_elliptical_blur(result_image, face_region, blur_strength, is_face=True)
            region_index += 1
            print(f"âœ“ å·²å¤„ç†è„¸éƒ¨åŒºåŸŸï¼ˆæ¤­åœ†å½¢æ¨¡ç³Šï¼‰")
        
        # å¤„ç†å…¶ä»–åŒºåŸŸï¼ˆä½¿ç”¨çŸ©å½¢æ¨¡ç³Šï¼‰
        other_regions = []
        if censor_chest and chest_region:
            other_regions.append(chest_region)
        if censor_groin and groin_region:
            other_regions.append(groin_region)
        
        for region in other_regions:
            result_image = self.apply_blur(result_image, region, blur_strength)
            region_index += 1
            print(f"âœ“ å·²å¤„ç†åŒºåŸŸ {region_index}/{len(regions_to_blur)}")
        
        # è½¬æ¢å›žtorchå¼ é‡æ ¼å¼
        result_tensor = torch.from_numpy(result_image.astype(np.float32) / 255.0).unsqueeze(0)
        
        print("âœ“ æ‰“ç å¤„ç†å®Œæˆï¼")
        return (result_tensor,)


# ç”¨äºŽå®žé™…é›†æˆOpenPoseçš„è¾…åŠ©ç±»
class OpenPoseDetector:
    """
    å®žé™…ä½¿ç”¨æ—¶ï¼Œè¿™ä¸ªç±»åº”è¯¥åŒ…å«çœŸæ­£çš„OpenPoseé›†æˆ
    """
    def __init__(self):
        # åˆå§‹åŒ–OpenPoseæ¨¡åž‹
        # å¯ä»¥ä½¿ç”¨ä»¥ä¸‹é€‰é¡¹ä¹‹ä¸€ï¼š
        # 1. openpose-python
        # 2. mediapipe
        # 3. mmpose
        # 4. å…¶ä»–å§¿æ€ä¼°è®¡åº“
        pass
    
    def detect(self, image):
        """
        æ£€æµ‹å›¾åƒä¸­çš„äººä½“å…³é”®ç‚¹
        è¿”å›žæ ¼å¼ï¼šnumpy array of shape (25, 3) for BODY_25 model
        """
        # å®žçŽ°å®žé™…çš„æ£€æµ‹é€»è¾‘
        pass


# èŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "AutoCensorWithOpenPose": AutoCensorWithOpenPose
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "AutoCensorWithOpenPose": "ðŸ³è‡ªåŠ¨æ‰“ç "
}